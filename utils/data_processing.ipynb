{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import zarr\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With NO Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote /hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/combined_meta_full_downsampled_no_bonecells.csv\n",
      "Kept rows: 2,095,668\n",
      "Dropped rows: 88,728\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "in_csv = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/combined_meta_full_downsampled.csv\"\n",
    "out_csv = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/combined_meta_full_downsampled_no_bonecells.csv\"\n",
    "\n",
    "label_col = \"cell_type\"\n",
    "# list of classes to drop\n",
    "drop_classes = [\n",
    "    \"Bone marrow cancer cells\",\n",
    "    \"Osteocytes\",\n",
    "    \"Osteoblasts\",\n",
    "    \"Osteoclasts\",\n",
    "    \"Chondrocytes\"\n",
    "    # add more labels here...\n",
    "]\n",
    "\n",
    "# stream in chunks and filter\n",
    "chunksize = 200_000\n",
    "first = True\n",
    "kept = 0\n",
    "dropped = 0\n",
    "\n",
    "for chunk in pd.read_csv(in_csv, chunksize=chunksize):\n",
    "    mask = ~chunk[label_col].isin(drop_classes)\n",
    "    kept += mask.sum()\n",
    "    dropped += (~mask).sum()\n",
    "    chunk = chunk[mask]\n",
    "    chunk.to_csv(out_csv, mode=\"w\" if first else \"a\", index=False, header=first)\n",
    "    first = False\n",
    "\n",
    "print(f\"Done. Wrote {out_csv}\")\n",
    "print(f\"Kept rows: {kept:,}\")\n",
    "print(f\"Dropped rows: {dropped:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original total: 2095668\n",
      "Subset total: 419134\n",
      "Example original class counts: {'Astrocytes': 100000, 'B cells': 100000, 'Breast cancer cells': 100000, 'Cardiac muscle cells': 58042, 'Colon cancer cells': 100000}\n",
      "Example subset class counts: {'Astrocytes': 20000, 'B cells': 20000, 'Breast cancer cells': 20000, 'Cardiac muscle cells': 11608, 'Colon cancer cells': 20000}\n",
      "\n",
      "Saved 20% subset to /hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/combined_meta_full_downsampled_no_bonecells_subset20pct.csv\n"
     ]
    }
   ],
   "source": [
    "import csv, math, random\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "in_csv   = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/combined_meta_full_downsampled_no_bonecells.csv\"\n",
    "out_csv  = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/combined_meta_full_downsampled_no_bonecells_subset20pct.csv\"\n",
    "label_col = \"cell_type\"\n",
    "subset_frac = 0.20\n",
    "seed = 23\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "def count_classes(path, label_col):\n",
    "    counts = Counter()\n",
    "    with open(path, \"r\", newline=\"\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        y_idx = header.index(label_col)\n",
    "        for row in reader:\n",
    "            counts[row[y_idx]] += 1\n",
    "    return counts, header, y_idx\n",
    "\n",
    "def compute_targets(counts, frac):\n",
    "    float_counts = {c: counts[c] * frac for c in counts}\n",
    "    floor_counts = {c: int(math.floor(v)) for c, v in float_counts.items()}\n",
    "    remainder = int(round(sum(float_counts.values()))) - sum(floor_counts.values())\n",
    "    # distribute remainder based on largest fractional part\n",
    "    frac_parts = sorted(\n",
    "        ((c, float_counts[c] - floor_counts[c]) for c in counts),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True,\n",
    "    )\n",
    "    targets = floor_counts.copy()\n",
    "    for i in range(remainder):\n",
    "        targets[frac_parts[i][0]] += 1\n",
    "    return targets\n",
    "\n",
    "def stream_subset(in_csv, out_csv, header, y_idx, targets):\n",
    "    remaining_in_class = defaultdict(int)\n",
    "    with open(in_csv, \"r\", newline=\"\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        _ = next(reader)\n",
    "        for row in reader:\n",
    "            remaining_in_class[row[y_idx]] += 1\n",
    "\n",
    "    rem_targets = targets.copy()\n",
    "\n",
    "    with open(in_csv, \"r\", newline=\"\") as f_in, open(out_csv, \"w\", newline=\"\") as f_out:\n",
    "        reader = csv.reader(f_in)\n",
    "        writer = csv.writer(f_out)\n",
    "        writer.writerow(header)\n",
    "        _ = next(reader)\n",
    "        for row in reader:\n",
    "            c = row[y_idx]\n",
    "            if rem_targets.get(c, 0) <= 0:\n",
    "                remaining_in_class[c] -= 1\n",
    "                continue\n",
    "            prob = rem_targets[c] / remaining_in_class[c]\n",
    "            if random.random() <= prob:\n",
    "                writer.writerow(row)\n",
    "                rem_targets[c] -= 1\n",
    "            remaining_in_class[c] -= 1\n",
    "\n",
    "def summarize(path, label_col):\n",
    "    counts = Counter()\n",
    "    total = 0\n",
    "    with open(path, \"r\", newline=\"\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        y_idx = header.index(label_col)\n",
    "        for row in reader:\n",
    "            counts[row[y_idx]] += 1\n",
    "            total += 1\n",
    "    dist = {k: v / total for k, v in counts.items()} if total > 0 else {}\n",
    "    return total, counts, dist\n",
    "\n",
    "# Run\n",
    "counts, header, y_idx = count_classes(in_csv, label_col)\n",
    "targets = compute_targets(counts, subset_frac)\n",
    "stream_subset(in_csv, out_csv, header, y_idx, targets)\n",
    "total, counts_sub, dist_sub = summarize(out_csv, label_col)\n",
    "\n",
    "print(\"Original total:\", sum(counts.values()))\n",
    "print(\"Subset total:\", total)\n",
    "print(\"Example original class counts:\", dict(list(counts.items())[:5]))\n",
    "print(\"Example subset class counts:\", dict(list(counts_sub.items())[:5]))\n",
    "print(f\"\\nSaved 20% subset to {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarse label, 20% subset of the downsampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and distribution:\n",
      "Cancer cells: 100,137 (23.89%)\n",
      "Immune cells: 80,000 (19.09%)\n",
      "Stromal cells: 53,394 (12.74%)\n",
      "Glial cells: 49,447 (11.80%)\n",
      "Muscle cells: 36,156 (8.63%)\n",
      "Endothelial cells: 20,000 (4.77%)\n",
      "Epithelial cells: 20,000 (4.77%)\n",
      "Erythrocytes: 20,000 (4.77%)\n",
      "Neurons: 20,000 (4.77%)\n",
      "Stem and progenitor cells: 20,000 (4.77%)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/combined_meta_full_downsampled_no_bonecells_subset20pct.csv\"\n",
    "label_col = \"cell_type_coarse\"\n",
    "\n",
    "counts = Counter()\n",
    "total = 0\n",
    "\n",
    "# Stream the CSV in chunks\n",
    "for chunk in pd.read_csv(file_path, usecols=[label_col], chunksize=100_000):\n",
    "    vals = chunk[label_col]\n",
    "    counts.update(vals)\n",
    "    total += len(vals)\n",
    "\n",
    "# Print results\n",
    "print(\"Counts and distribution:\")\n",
    "for label, count in counts.most_common():\n",
    "    pct = count / total * 100\n",
    "    print(f\"{label}: {count:,} ({pct:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine label 20% subset of the downsampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and distribution:\n",
      "Astrocytes: 20,000 (4.77%)\n",
      "B cells: 20,000 (4.77%)\n",
      "Breast cancer cells: 20,000 (4.77%)\n",
      "Colon cancer cells: 20,000 (4.77%)\n",
      "Endothelial cells: 20,000 (4.77%)\n",
      "Epithelial cells: 20,000 (4.77%)\n",
      "Erythrocytes: 20,000 (4.77%)\n",
      "Fibroblasts: 20,000 (4.77%)\n",
      "Myeloid cells: 20,000 (4.77%)\n",
      "NK cells: 20,000 (4.77%)\n",
      "Neurons: 20,000 (4.77%)\n",
      "Oligodendrocytes: 20,000 (4.77%)\n",
      "Ovary cancer cells: 20,000 (4.77%)\n",
      "Smooth muscle cells: 20,000 (4.77%)\n",
      "Stem and progenitor cells: 20,000 (4.77%)\n",
      "Stromal cells: 20,000 (4.77%)\n",
      "T cells: 20,000 (4.77%)\n",
      "Skin cancer cells: 14,605 (3.48%)\n",
      "Lung cancer cells: 13,327 (3.18%)\n",
      "Cardiac muscle cells: 11,608 (2.77%)\n",
      "Pancreas cancer cells: 10,121 (2.41%)\n",
      "Microglia: 9,447 (2.25%)\n",
      "Pericytes: 9,368 (2.24%)\n",
      "Skeletal muscle cells: 4,548 (1.09%)\n",
      "Mesangial cells: 4,026 (0.96%)\n",
      "Liver cancer cells: 2,084 (0.50%)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/combined_meta_full_downsampled_no_bonecells_subset20pct.csv\"\n",
    "label_col = \"cell_type\"\n",
    "\n",
    "counts = Counter()\n",
    "total = 0\n",
    "\n",
    "# Stream the CSV in chunks\n",
    "for chunk in pd.read_csv(file_path, usecols=[label_col], chunksize=100_000):\n",
    "    vals = chunk[label_col]\n",
    "    counts.update(vals)\n",
    "    total += len(vals)\n",
    "\n",
    "# Print results\n",
    "print(\"Counts and distribution:\")\n",
    "for label, count in counts.most_common():\n",
    "    pct = count / total * 100\n",
    "    print(f\"{label}: {count:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mapping to /hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/class_to_idx_coarse.json\n",
      "{'Cancer cells': 0, 'Endothelial cells': 1, 'Epithelial cells': 2, 'Erythrocytes': 3, 'Glial cells': 4, 'Immune cells': 5, 'Muscle cells': 6, 'Neurons': 7, 'Stem and progenitor cells': 8, 'Stromal cells': 9}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "subset_csv = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/combined_meta_full_downsampled_no_bonecells_subset20pct.csv\"\n",
    "out_json   = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/class_to_idx_coarse.json\"\n",
    "label_col  = \"cell_type_coarse\"\n",
    "\n",
    "# Load subset\n",
    "df = pd.read_csv(subset_csv)\n",
    "\n",
    "# Get sorted unique classes\n",
    "classes = sorted(df[label_col].unique())\n",
    "\n",
    "# Build mapping {class_name: id}\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "# Save to JSON\n",
    "with open(out_json, \"w\") as f:\n",
    "    json.dump(class_to_idx, f, indent=2)\n",
    "\n",
    "print(\"Saved mapping to\", out_json)\n",
    "print(class_to_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test split of the 20% subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 329,259 rows -> /hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/20pct_train.csv\n",
      "Val:   53,375 rows -> /hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/20pct_val.csv\n",
      "Test:  36,500 rows -> /hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/20pct_test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "\n",
    "in_csv   = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/combined_meta_full_downsampled_no_bonecells_subset20pct.csv\"  \n",
    "train_csv = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/20pct_train.csv\"\n",
    "val_csv   = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/20pct_val.csv\"\n",
    "test_csv  = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/20pct_test.csv\"\n",
    "\n",
    "label_col = \"cell_type\"\n",
    "# Columns to build a stable, unique key per row. Adjust if needed.\n",
    "key_cols = [\"slide_id\", \"nucleus_id\", \"cell_id\"]\n",
    "seed = \"23\"  # string is fine\n",
    "\n",
    "chunksize = 200_000\n",
    "first = True\n",
    "\n",
    "# Make sure parents exist\n",
    "os.makedirs(os.path.dirname(train_csv), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(val_csv), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(test_csv), exist_ok=True)\n",
    "\n",
    "# We only need the columns we will write\n",
    "# If you want to keep all columns, set usecols=None\n",
    "usecols = None  # keep all columns\n",
    "\n",
    "def row_key(row):\n",
    "    parts = []\n",
    "    for c in key_cols:\n",
    "        parts.append(str(row[c]) if c in row and pd.notna(row[c]) else \"\")\n",
    "    return \"|\".join(parts)\n",
    "\n",
    "def assign_bucket(row):\n",
    "    # Deterministic hash in [0,1)\n",
    "    k = row_key(row) + \"|\" + seed + \"|\" + str(row[label_col])\n",
    "    h = hashlib.md5(k.encode(\"utf-8\")).hexdigest()\n",
    "    r = int(h, 16) / float(2**128)\n",
    "    # 0.0 to 0.7999 -> train, 0.8 to 0.8999 -> val, else test\n",
    "    if r < 0.8:\n",
    "        return \"train\"\n",
    "    elif r < 0.9:\n",
    "        return \"val\"\n",
    "    else:\n",
    "        return \"test\"\n",
    "\n",
    "# Counters\n",
    "n_train = n_val = n_test = 0\n",
    "\n",
    "for chunk in pd.read_csv(in_csv, chunksize=chunksize, usecols=usecols):\n",
    "    # Safety: if any key col missing in the file, create empty string column\n",
    "    for c in key_cols:\n",
    "        if c not in chunk.columns:\n",
    "            chunk[c] = \"\"\n",
    "\n",
    "    # Compute split per row\n",
    "    split = chunk.apply(assign_bucket, axis=1)\n",
    "\n",
    "    # Write each split\n",
    "    tmask = split == \"train\"\n",
    "    vmask = split == \"val\"\n",
    "    smask = split == \"test\"\n",
    "\n",
    "    if tmask.any():\n",
    "        chunk.loc[tmask].to_csv(train_csv, mode=\"w\" if first else \"a\", index=False, header=first)\n",
    "        n_train += int(tmask.sum())\n",
    "    if vmask.any():\n",
    "        chunk.loc[vmask].to_csv(val_csv, mode=\"w\" if first else \"a\", index=False, header=first)\n",
    "        n_val += int(vmask.sum())\n",
    "    if smask.any():\n",
    "        chunk.loc[smask].to_csv(test_csv, mode=\"w\" if first else \"a\", index=False, header=first)\n",
    "        n_test += int(smask.sum())\n",
    "\n",
    "    first = False  # headers written after first batch\n",
    "\n",
    "print(f\"Train: {n_train:,} rows -> {train_csv}\")\n",
    "print(f\"Val:   {n_val:,} rows -> {val_csv}\")\n",
    "print(f\"Test:  {n_test:,} rows -> {test_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and distribution:\n",
      "Colon cancer cells: 20,000 (6.07%)\n",
      "Ovary cancer cells: 20,000 (6.07%)\n",
      "Smooth muscle cells: 19,102 (5.80%)\n",
      "Stromal cells: 19,030 (5.78%)\n",
      "Breast cancer cells: 17,502 (5.32%)\n",
      "Fibroblasts: 17,305 (5.26%)\n",
      "Neurons: 16,973 (5.15%)\n",
      "Endothelial cells: 16,281 (4.94%)\n",
      "B cells: 15,859 (4.82%)\n",
      "Myeloid cells: 15,808 (4.80%)\n",
      "NK cells: 15,264 (4.64%)\n",
      "Oligodendrocytes: 15,056 (4.57%)\n",
      "Skin cancer cells: 14,605 (4.44%)\n",
      "T cells: 14,239 (4.32%)\n",
      "Epithelial cells: 14,230 (4.32%)\n",
      "Erythrocytes: 13,725 (4.17%)\n",
      "Astrocytes: 12,667 (3.85%)\n",
      "Stem and progenitor cells: 11,778 (3.58%)\n",
      "Pancreas cancer cells: 10,121 (3.07%)\n",
      "Lung cancer cells: 8,943 (2.72%)\n",
      "Microglia: 6,574 (2.00%)\n",
      "Pericytes: 6,279 (1.91%)\n",
      "Mesangial cells: 4,026 (1.22%)\n",
      "Skeletal muscle cells: 3,182 (0.97%)\n",
      "Cardiac muscle cells: 710 (0.22%)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/20pct_train.csv\"\n",
    "label_col = \"cell_type\"\n",
    "\n",
    "counts = Counter()\n",
    "total = 0\n",
    "\n",
    "# Stream the CSV in chunks\n",
    "for chunk in pd.read_csv(file_path, usecols=[label_col], chunksize=100_000):\n",
    "    vals = chunk[label_col]\n",
    "    counts.update(vals)\n",
    "    total += len(vals)\n",
    "\n",
    "# Print results\n",
    "print(\"Counts and distribution:\")\n",
    "for label, count in counts.most_common():\n",
    "    pct = count / total * 100\n",
    "    print(f\"{label}: {count:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and distribution:\n",
      "Cancer cells: 91,171 (27.69%)\n",
      "Immune cells: 61,170 (18.58%)\n",
      "Stromal cells: 46,640 (14.17%)\n",
      "Glial cells: 34,297 (10.42%)\n",
      "Muscle cells: 22,994 (6.98%)\n",
      "Neurons: 16,973 (5.15%)\n",
      "Endothelial cells: 16,281 (4.94%)\n",
      "Epithelial cells: 14,230 (4.32%)\n",
      "Erythrocytes: 13,725 (4.17%)\n",
      "Stem and progenitor cells: 11,778 (3.58%)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/20pct_train.csv\"\n",
    "label_col = \"cell_type_coarse\"\n",
    "\n",
    "counts = Counter()\n",
    "total = 0\n",
    "\n",
    "# Stream the CSV in chunks\n",
    "for chunk in pd.read_csv(file_path, usecols=[label_col], chunksize=100_000):\n",
    "    vals = chunk[label_col]\n",
    "    counts.update(vals)\n",
    "    total += len(vals)\n",
    "\n",
    "# Print results\n",
    "print(\"Counts and distribution:\")\n",
    "for label, count in counts.most_common():\n",
    "    pct = count / total * 100\n",
    "    print(f\"{label}: {count:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original dataset with background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and distribution:\n",
      "Epithelial cells: 959,755 (12.61%)\n",
      "Myeloid cells: 956,707 (12.57%)\n",
      "Stem and progenitor cells: 827,997 (10.88%)\n",
      "T cells: 807,476 (10.61%)\n",
      "B cells: 699,126 (9.19%)\n",
      "Endothelial cells: 615,478 (8.09%)\n",
      "Fibroblasts: 376,857 (4.95%)\n",
      "Smooth muscle cells: 309,461 (4.07%)\n",
      "Neurons: 281,591 (3.70%)\n",
      "Stromal cells: 247,968 (3.26%)\n",
      "Erythrocytes: 201,938 (2.65%)\n",
      "Cardiac muscle cells: 192,246 (2.53%)\n",
      "Ovary cancer cells: 190,324 (2.50%)\n",
      "Colon cancer cells: 176,040 (2.31%)\n",
      "Oligodendrocytes: 95,514 (1.26%)\n",
      "NK cells: 92,899 (1.22%)\n",
      "Skin cancer cells: 73,025 (0.96%)\n",
      "Mesangial cells: 68,076 (0.89%)\n",
      "Osteoblasts: 64,389 (0.85%)\n",
      "Lung cancer cells: 60,874 (0.80%)\n",
      "Astrocytes: 56,141 (0.74%)\n",
      "Pericytes: 54,472 (0.72%)\n",
      "Pancreas cancer cells: 50,607 (0.66%)\n",
      "Chondrocytes: 31,329 (0.41%)\n",
      "Skeletal muscle cells: 30,656 (0.40%)\n",
      "Schwann cells: 24,718 (0.32%)\n",
      "Microglia: 21,921 (0.29%)\n",
      "Liver cancer cells: 10,418 (0.14%)\n",
      "Osteoclasts: 9,048 (0.12%)\n",
      "Osteocytes: 8,236 (0.11%)\n",
      "Bone marrow cancer cells: 5,762 (0.08%)\n",
      "OPCs: 3,022 (0.04%)\n",
      "Ependymal cells: 2,627 (0.03%)\n",
      "Brain cancer cells: 2,344 (0.03%)\n",
      "Kidney cancer cells: 1,128 (0.01%)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/hpc/group/jilab/boxuan/data/combined_full/combined_meta_cell_type.csv\"\n",
    "label_col = \"cell_type\"\n",
    "\n",
    "counts = Counter()\n",
    "total = 0\n",
    "\n",
    "# Stream the CSV in chunks\n",
    "for chunk in pd.read_csv(file_path, usecols=[label_col], chunksize=100_000):\n",
    "    vals = chunk[label_col]\n",
    "    counts.update(vals)\n",
    "    total += len(vals)\n",
    "\n",
    "# Print results\n",
    "print(\"Counts and distribution:\")\n",
    "for label, count in counts.most_common():\n",
    "    pct = count / total * 100\n",
    "    print(f\"{label}: {count:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling to 20:1 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class policy summary: drop=4, keep_all=17, cap=14\n",
      "Pass 2 done. Total rows seen 7,610,170. Wrote keep_all 758,085. Sharded 6,842,964. Dropped 9,121.\n",
      "Appended 100,000 rows for class Myeloid cells\n",
      "Appended 100,000 rows for class Smooth muscle cells\n",
      "Appended 100,000 rows for class Fibroblasts\n",
      "Appended 100,000 rows for class Epithelial cells\n",
      "Appended 100,000 rows for class Endothelial cells\n",
      "Appended 100,000 rows for class T cells\n",
      "Appended 100,000 rows for class B cells\n",
      "Appended 100,000 rows for class Cardiac muscle cells\n",
      "Appended 100,000 rows for class Stromal cells\n",
      "Appended 100,000 rows for class Erythrocytes\n",
      "Appended 100,000 rows for class Neurons\n",
      "Appended 100,000 rows for class Ovary cancer cells\n",
      "Appended 100,000 rows for class Stem and progenitor cells\n",
      "Appended 100,000 rows for class Colon cancer cells\n",
      "Done. Final file: /hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled.csv\n",
      "Rows appended from shards 1,400,000. Now you can remove temp dir if you want: /hpc/group/jilab/rz179/cellpt/combined/withBackground/tmp_celltype_shards\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Inputs\n",
    "in_csv = \"/hpc/group/jilab/boxuan/data/combined_full/combined_meta_cell_type.csv\"\n",
    "out_csv = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled.csv\"\n",
    "tmp_dir = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/tmp_celltype_shards\"\n",
    "label_col = \"cell_type\"\n",
    "keep_cols = [\n",
    "    \"slide_id\", \"cell_type_coarse\", \"cell_type\",\n",
    "    \"raw_img_path\", \"mask_target_img_path\", \"mask_context_img_path\",\n",
    "    \"nucleus_id\", \"cell_id\",\n",
    "]\n",
    "chunksize = 200_000\n",
    "cap = 100_000\n",
    "min_keep = 5_000\n",
    "seed = 23\n",
    "random.seed(seed)\n",
    "\n",
    "Path(tmp_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Pass 1. Count classes\n",
    "counts = Counter()\n",
    "for chunk in pd.read_csv(in_csv, usecols=[label_col], chunksize=chunksize):\n",
    "    counts.update(chunk[label_col])\n",
    "\n",
    "# Decide policy\n",
    "policy = {}\n",
    "for cls, n in counts.items():\n",
    "    if n < min_keep:\n",
    "        policy[cls] = (\"drop\", 0)\n",
    "    elif n <= cap:\n",
    "        policy[cls] = (\"keep_all\", n)\n",
    "    else:\n",
    "        policy[cls] = (\"cap\", cap)\n",
    "\n",
    "num_drop = sum(1 for v in policy.values() if v[0] == \"drop\")\n",
    "num_keep_all = sum(1 for v in policy.values() if v[0] == \"keep_all\")\n",
    "num_cap = sum(1 for v in policy.values() if v[0] == \"cap\")\n",
    "print(f\"Class policy summary: drop={num_drop}, keep_all={num_keep_all}, cap={num_cap}\")\n",
    "\n",
    "# Prepare final file with header\n",
    "with open(out_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(keep_cols)\n",
    "\n",
    "# Helper to make safe shard file names\n",
    "def shard_path_for_class(cls_name: str) -> Path:\n",
    "    safe = \"\".join(ch if ch.isalnum() or ch in \"._-\" else \"_\" for ch in str(cls_name))\n",
    "    return Path(tmp_dir) / f\"class_{safe}.csv\"\n",
    "\n",
    "# Pass 2. Stream and write\n",
    "# For keep_all classes, write directly to final\n",
    "# For cap classes, write into class shard files\n",
    "shard_writers = {}\n",
    "shard_files = {}\n",
    "\n",
    "def get_shard_writer(cls):\n",
    "    if cls in shard_writers:\n",
    "        return shard_writers[cls]\n",
    "    p = shard_path_for_class(cls)\n",
    "    f = open(p, \"w\", newline=\"\")\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(keep_cols)\n",
    "    shard_files[cls] = f\n",
    "    shard_writers[cls] = w\n",
    "    return w\n",
    "\n",
    "usecols = list(set(keep_cols + [label_col]))\n",
    "total_rows = 0\n",
    "kept_direct = 0\n",
    "sharded = 0\n",
    "dropped = 0\n",
    "\n",
    "with open(out_csv, \"a\", newline=\"\") as f_out:\n",
    "    out_writer = csv.writer(f_out)\n",
    "    for chunk in pd.read_csv(in_csv, usecols=usecols, chunksize=chunksize):\n",
    "        total_rows += len(chunk)\n",
    "        # restrict to the columns we want to write\n",
    "        chunk = chunk[keep_cols]\n",
    "        for row in chunk.itertuples(index=False, name=None):\n",
    "            # row order matches keep_cols\n",
    "            cls = row[keep_cols.index(label_col)]\n",
    "            act, k = policy.get(cls, (\"drop\", 0))\n",
    "\n",
    "            if act == \"drop\":\n",
    "                dropped += 1\n",
    "                continue\n",
    "            if act == \"keep_all\":\n",
    "                out_writer.writerow(row)\n",
    "                kept_direct += 1\n",
    "            else:\n",
    "                # cap policy\n",
    "                w = get_shard_writer(cls)\n",
    "                w.writerow(row)\n",
    "                sharded += 1\n",
    "\n",
    "# Close all shard files\n",
    "for f in shard_files.values():\n",
    "    f.close()\n",
    "\n",
    "print(f\"Pass 2 done. Total rows seen {total_rows:,}. Wrote keep_all {kept_direct:,}. Sharded {sharded:,}. Dropped {dropped:,}.\")\n",
    "\n",
    "# Pass 3. For each capped class shard, do reservoir sample of size cap, append to final\n",
    "def reservoir_sample_from_csv(csv_path: Path, k: int, header=True):\n",
    "    \"\"\"Return a list of up to k rows from csv_path using Algorithm R.\"\"\"\n",
    "    sample = []\n",
    "    with open(csv_path, \"r\", newline=\"\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        if header:\n",
    "            next(reader, None)\n",
    "        seen = 0\n",
    "        for row in reader:\n",
    "            seen += 1\n",
    "            if len(sample) < k:\n",
    "                sample.append(row)\n",
    "            else:\n",
    "                j = random.randint(1, seen)\n",
    "                if j <= k:\n",
    "                    sample[j - 1] = row\n",
    "    return sample\n",
    "\n",
    "added_from_shards = 0\n",
    "with open(out_csv, \"a\", newline=\"\") as f_out:\n",
    "    out_writer = csv.writer(f_out)\n",
    "    for cls, (act, k) in policy.items():\n",
    "        if act != \"cap\":\n",
    "            continue\n",
    "        shard_path = shard_path_for_class(cls)\n",
    "        if not shard_path.exists():\n",
    "            # No rows ended up in this shard. Skip.\n",
    "            continue\n",
    "        # For safety, compute target k as min(cap, actual rows)\n",
    "        # This also protects against off by ones\n",
    "        # Count rows quickly\n",
    "        with open(shard_path, \"r\") as f:\n",
    "            rows_in_file = sum(1 for _ in f) - 1  # minus header\n",
    "        target_k = min(k, rows_in_file)\n",
    "        if target_k <= 0:\n",
    "            continue\n",
    "        sample_rows = reservoir_sample_from_csv(shard_path, target_k, header=True)\n",
    "        out_writer.writerows(sample_rows)\n",
    "        added_from_shards += len(sample_rows)\n",
    "        print(f\"Appended {len(sample_rows):,} rows for class {cls}\")\n",
    "\n",
    "print(f\"Done. Final file: {out_csv}\")\n",
    "print(f\"Rows appended from shards {added_from_shards:,}. Now you can remove temp dir if you want: {tmp_dir}\")\n",
    "\n",
    "# Optional cleanup\n",
    "# shutil.rmtree(tmp_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and distribution:\n",
      "Myeloid cells: 100,000 (4.63%)\n",
      "Smooth muscle cells: 100,000 (4.63%)\n",
      "Fibroblasts: 100,000 (4.63%)\n",
      "Epithelial cells: 100,000 (4.63%)\n",
      "Endothelial cells: 100,000 (4.63%)\n",
      "T cells: 100,000 (4.63%)\n",
      "B cells: 100,000 (4.63%)\n",
      "Cardiac muscle cells: 100,000 (4.63%)\n",
      "Stromal cells: 100,000 (4.63%)\n",
      "Erythrocytes: 100,000 (4.63%)\n",
      "Neurons: 100,000 (4.63%)\n",
      "Ovary cancer cells: 100,000 (4.63%)\n",
      "Stem and progenitor cells: 100,000 (4.63%)\n",
      "Colon cancer cells: 100,000 (4.63%)\n",
      "Oligodendrocytes: 95,514 (4.43%)\n",
      "NK cells: 92,899 (4.30%)\n",
      "Skin cancer cells: 73,025 (3.38%)\n",
      "Mesangial cells: 68,076 (3.15%)\n",
      "Osteoblasts: 64,389 (2.98%)\n",
      "Lung cancer cells: 60,874 (2.82%)\n",
      "Astrocytes: 56,141 (2.60%)\n",
      "Pericytes: 54,472 (2.52%)\n",
      "Pancreas cancer cells: 50,607 (2.34%)\n",
      "Chondrocytes: 31,329 (1.45%)\n",
      "Skeletal muscle cells: 30,656 (1.42%)\n",
      "Schwann cells: 24,718 (1.15%)\n",
      "Microglia: 21,921 (1.02%)\n",
      "Liver cancer cells: 10,418 (0.48%)\n",
      "Osteoclasts: 9,048 (0.42%)\n",
      "Osteocytes: 8,236 (0.38%)\n",
      "Bone marrow cancer cells: 5,762 (0.27%)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled.csv\"\n",
    "label_col = \"cell_type\"\n",
    "\n",
    "counts = Counter()\n",
    "total = 0\n",
    "\n",
    "# Stream the CSV in chunks\n",
    "for chunk in pd.read_csv(file_path, usecols=[label_col], chunksize=100_000):\n",
    "    vals = chunk[label_col]\n",
    "    counts.update(vals)\n",
    "    total += len(vals)\n",
    "\n",
    "# Print results\n",
    "print(\"Counts and distribution:\")\n",
    "for label, count in counts.most_common():\n",
    "    pct = count / total * 100\n",
    "    print(f\"{label}: {count:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Bone cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote /hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled_no_bonecells.csv\n",
      "Kept rows: 2,039,321\n",
      "Dropped rows: 118,764\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "in_csv = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled.csv\"\n",
    "out_csv = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled_no_bonecells.csv\"\n",
    "\n",
    "label_col = \"cell_type\"\n",
    "# list of classes to drop\n",
    "drop_classes = [\n",
    "    \"Bone marrow cancer cells\",\n",
    "    \"Osteocytes\",\n",
    "    \"Osteoblasts\",\n",
    "    \"Osteoclasts\",\n",
    "    \"Chondrocytes\"\n",
    "    # add more labels here...\n",
    "]\n",
    "\n",
    "# stream in chunks and filter\n",
    "chunksize = 200_000\n",
    "first = True\n",
    "kept = 0\n",
    "dropped = 0\n",
    "\n",
    "for chunk in pd.read_csv(in_csv, chunksize=chunksize):\n",
    "    mask = ~chunk[label_col].isin(drop_classes)\n",
    "    kept += mask.sum()\n",
    "    dropped += (~mask).sum()\n",
    "    chunk = chunk[mask]\n",
    "    chunk.to_csv(out_csv, mode=\"w\" if first else \"a\", index=False, header=first)\n",
    "    first = False\n",
    "\n",
    "print(f\"Done. Wrote {out_csv}\")\n",
    "print(f\"Kept rows: {kept:,}\")\n",
    "print(f\"Dropped rows: {dropped:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and distribution:\n",
      "Myeloid cells: 100,000 (4.90%)\n",
      "Smooth muscle cells: 100,000 (4.90%)\n",
      "Fibroblasts: 100,000 (4.90%)\n",
      "Epithelial cells: 100,000 (4.90%)\n",
      "Endothelial cells: 100,000 (4.90%)\n",
      "T cells: 100,000 (4.90%)\n",
      "B cells: 100,000 (4.90%)\n",
      "Cardiac muscle cells: 100,000 (4.90%)\n",
      "Stromal cells: 100,000 (4.90%)\n",
      "Erythrocytes: 100,000 (4.90%)\n",
      "Neurons: 100,000 (4.90%)\n",
      "Ovary cancer cells: 100,000 (4.90%)\n",
      "Stem and progenitor cells: 100,000 (4.90%)\n",
      "Colon cancer cells: 100,000 (4.90%)\n",
      "Oligodendrocytes: 95,514 (4.68%)\n",
      "NK cells: 92,899 (4.56%)\n",
      "Skin cancer cells: 73,025 (3.58%)\n",
      "Mesangial cells: 68,076 (3.34%)\n",
      "Lung cancer cells: 60,874 (2.99%)\n",
      "Astrocytes: 56,141 (2.75%)\n",
      "Pericytes: 54,472 (2.67%)\n",
      "Pancreas cancer cells: 50,607 (2.48%)\n",
      "Skeletal muscle cells: 30,656 (1.50%)\n",
      "Schwann cells: 24,718 (1.21%)\n",
      "Microglia: 21,921 (1.07%)\n",
      "Liver cancer cells: 10,418 (0.51%)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled_no_bonecells.csv\"\n",
    "label_col = \"cell_type\"\n",
    "\n",
    "counts = Counter()\n",
    "total = 0\n",
    "\n",
    "# Stream the CSV in chunks\n",
    "for chunk in pd.read_csv(file_path, usecols=[label_col], chunksize=100_000):\n",
    "    vals = chunk[label_col]\n",
    "    counts.update(vals)\n",
    "    total += len(vals)\n",
    "\n",
    "# Print results\n",
    "print(\"Counts and distribution:\")\n",
    "for label, count in counts.most_common():\n",
    "    pct = count / total * 100\n",
    "    print(f\"{label}: {count:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include COARSE LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote chunk 0, rows 200000, total 200000\n",
      "Wrote chunk 1, rows 200000, total 400000\n",
      "Wrote chunk 2, rows 200000, total 600000\n",
      "Wrote chunk 3, rows 200000, total 800000\n",
      "Wrote chunk 4, rows 200000, total 1000000\n",
      "Wrote chunk 5, rows 200000, total 1200000\n",
      "Wrote chunk 6, rows 200000, total 1400000\n",
      "Wrote chunk 7, rows 200000, total 1600000\n",
      "Wrote chunk 8, rows 200000, total 1800000\n",
      "Wrote chunk 9, rows 200000, total 2000000\n",
      "Wrote chunk 10, rows 39321, total 2039321\n",
      "===================================================\n",
      "Total rows processed: 2039321\n",
      "Rows mapped successfully: 2039321\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# --- paths ---\n",
    "in_csv  = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled_no_bonecells.csv\"\n",
    "out_csv = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled_no_bonecells_withCoarse.csv\"\n",
    "mapping_json = \"/hpc/group/jilab/rz179/cellpt/combined/fine_to_coarse_map.json\"   # <- update to your json path\n",
    "\n",
    "# --- load mapping ---\n",
    "with open(mapping_json, \"r\") as f:\n",
    "    fine_to_coarse = json.load(f)\n",
    "\n",
    "cell_col = \"cell_type\"\n",
    "coarse_col = \"cell_type_coarse\"\n",
    "chunksize = 200_000   # adjust to your memory\n",
    "\n",
    "# --- prepare output ---\n",
    "if os.path.exists(out_csv):\n",
    "    os.remove(out_csv)\n",
    "\n",
    "unmapped = Counter()\n",
    "row_count = 0\n",
    "updated_count = 0\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv(in_csv, chunksize=chunksize)):\n",
    "    # map fine -> coarse\n",
    "    mapped = chunk[cell_col].map(fine_to_coarse)\n",
    "\n",
    "    # track unmapped\n",
    "    missing_mask = mapped.isna()\n",
    "    if missing_mask.any():\n",
    "        for lbl, cnt in chunk.loc[missing_mask, cell_col].value_counts().items():\n",
    "            unmapped[lbl] += int(cnt)\n",
    "\n",
    "    # overwrite or create coarse column\n",
    "    chunk[coarse_col] = mapped\n",
    "    updated_count += int(chunk[coarse_col].notna().sum())\n",
    "    row_count += len(chunk)\n",
    "\n",
    "    # write out\n",
    "    mode = \"w\" if i == 0 else \"a\"\n",
    "    header = (i == 0)\n",
    "    chunk.to_csv(out_csv, index=False, mode=mode, header=header)\n",
    "\n",
    "    print(f\"Wrote chunk {i}, rows {len(chunk)}, total {row_count}\")\n",
    "\n",
    "print(\"===================================================\")\n",
    "print(f\"Total rows processed: {row_count}\")\n",
    "print(f\"Rows mapped successfully: {updated_count}\")\n",
    "if unmapped:\n",
    "    print(\"Unmapped labels found:\")\n",
    "    for k, v in unmapped.most_common():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(\"Add them to your JSON if needed and rerun.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and distribution:\n",
      "Cancer cells: 394,924 (19.37%)\n",
      "Immune cells: 392,899 (19.27%)\n",
      "Stromal cells: 322,548 (15.82%)\n",
      "Muscle cells: 230,656 (11.31%)\n",
      "Glial cells: 198,294 (9.72%)\n",
      "Epithelial cells: 100,000 (4.90%)\n",
      "Endothelial cells: 100,000 (4.90%)\n",
      "Erythrocytes: 100,000 (4.90%)\n",
      "Neurons: 100,000 (4.90%)\n",
      "Stem and progenitor cells: 100,000 (4.90%)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled_no_bonecells_withCoarse.csv\"\n",
    "label_col = \"cell_type_coarse\"\n",
    "\n",
    "counts = Counter()\n",
    "total = 0\n",
    "\n",
    "# Stream the CSV in chunks\n",
    "for chunk in pd.read_csv(file_path, usecols=[label_col], chunksize=100_000):\n",
    "    vals = chunk[label_col]\n",
    "    counts.update(vals)\n",
    "    total += len(vals)\n",
    "\n",
    "# Print results\n",
    "print(\"Counts and distribution:\")\n",
    "for label, count in counts.most_common():\n",
    "    pct = count / total * 100\n",
    "    print(f\"{label}: {count:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split based on fine cell_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original total: 2039321\n",
      "Subset total: 407864\n",
      "Example original class counts: {'Pericytes': 54472, 'NK cells': 92899, 'Lung cancer cells': 60874, 'Skeletal muscle cells': 30656, 'Schwann cells': 24718}\n",
      "Example subset class counts: {'Pericytes': 10894, 'NK cells': 18580, 'Lung cancer cells': 12175, 'Skeletal muscle cells': 6131, 'Schwann cells': 4944}\n",
      "\n",
      "Saved 20% subset to /hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled_no_bonecells_withCoarse_20pct.csv\n"
     ]
    }
   ],
   "source": [
    "import csv, math, random\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "in_csv   = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled_no_bonecells_withCoarse.csv\"\n",
    "out_csv  = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled_no_bonecells_withCoarse_20pct.csv\"\n",
    "label_col = \"cell_type\"\n",
    "subset_frac = 0.20\n",
    "seed = 23\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "def count_classes(path, label_col):\n",
    "    counts = Counter()\n",
    "    with open(path, \"r\", newline=\"\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        y_idx = header.index(label_col)\n",
    "        for row in reader:\n",
    "            counts[row[y_idx]] += 1\n",
    "    return counts, header, y_idx\n",
    "\n",
    "def compute_targets(counts, frac):\n",
    "    float_counts = {c: counts[c] * frac for c in counts}\n",
    "    floor_counts = {c: int(math.floor(v)) for c, v in float_counts.items()}\n",
    "    remainder = int(round(sum(float_counts.values()))) - sum(floor_counts.values())\n",
    "    # distribute remainder based on largest fractional part\n",
    "    frac_parts = sorted(\n",
    "        ((c, float_counts[c] - floor_counts[c]) for c in counts),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True,\n",
    "    )\n",
    "    targets = floor_counts.copy()\n",
    "    for i in range(remainder):\n",
    "        targets[frac_parts[i][0]] += 1\n",
    "    return targets\n",
    "\n",
    "def stream_subset(in_csv, out_csv, header, y_idx, targets):\n",
    "    remaining_in_class = defaultdict(int)\n",
    "    with open(in_csv, \"r\", newline=\"\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        _ = next(reader)\n",
    "        for row in reader:\n",
    "            remaining_in_class[row[y_idx]] += 1\n",
    "\n",
    "    rem_targets = targets.copy()\n",
    "\n",
    "    with open(in_csv, \"r\", newline=\"\") as f_in, open(out_csv, \"w\", newline=\"\") as f_out:\n",
    "        reader = csv.reader(f_in)\n",
    "        writer = csv.writer(f_out)\n",
    "        writer.writerow(header)\n",
    "        _ = next(reader)\n",
    "        for row in reader:\n",
    "            c = row[y_idx]\n",
    "            if rem_targets.get(c, 0) <= 0:\n",
    "                remaining_in_class[c] -= 1\n",
    "                continue\n",
    "            prob = rem_targets[c] / remaining_in_class[c]\n",
    "            if random.random() <= prob:\n",
    "                writer.writerow(row)\n",
    "                rem_targets[c] -= 1\n",
    "            remaining_in_class[c] -= 1\n",
    "\n",
    "def summarize(path, label_col):\n",
    "    counts = Counter()\n",
    "    total = 0\n",
    "    with open(path, \"r\", newline=\"\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        y_idx = header.index(label_col)\n",
    "        for row in reader:\n",
    "            counts[row[y_idx]] += 1\n",
    "            total += 1\n",
    "    dist = {k: v / total for k, v in counts.items()} if total > 0 else {}\n",
    "    return total, counts, dist\n",
    "\n",
    "# Run\n",
    "counts, header, y_idx = count_classes(in_csv, label_col)\n",
    "targets = compute_targets(counts, subset_frac)\n",
    "stream_subset(in_csv, out_csv, header, y_idx, targets)\n",
    "total, counts_sub, dist_sub = summarize(out_csv, label_col)\n",
    "\n",
    "print(\"Original total:\", sum(counts.values()))\n",
    "print(\"Subset total:\", total)\n",
    "print(\"Example original class counts:\", dict(list(counts.items())[:5]))\n",
    "print(\"Example subset class counts:\", dict(list(counts_sub.items())[:5]))\n",
    "print(f\"\\nSaved 20% subset to {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 325,854 rows -> /hpc/group/jilab/rz179/cellpt/combined/withBackground/20pct_train.csv\n",
      "Val:   40,838 rows -> /hpc/group/jilab/rz179/cellpt/combined/withBackground/20pct_val.csv\n",
      "Test:  41,172 rows -> /hpc/group/jilab/rz179/cellpt/combined/withBackground/20pct_test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "\n",
    "in_csv   = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled_no_bonecells_withCoarse_20pct.csv\"   #our base dataset. 20:1\n",
    "train_csv = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/20pct_train.csv\"\n",
    "val_csv   = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/20pct_val.csv\"\n",
    "test_csv  = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/20pct_test.csv\"\n",
    "\n",
    "label_col = \"cell_type\"\n",
    "# Columns to build a stable, unique key per row. Adjust if needed.\n",
    "key_cols = [\"slide_id\", \"nucleus_id\", \"cell_id\"]\n",
    "seed = \"23\"  # string is fine\n",
    "\n",
    "chunksize = 200_000\n",
    "first = True\n",
    "\n",
    "# Make sure parents exist\n",
    "os.makedirs(os.path.dirname(train_csv), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(val_csv), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(test_csv), exist_ok=True)\n",
    "\n",
    "# We only need the columns we will write\n",
    "# If you want to keep all columns, set usecols=None\n",
    "usecols = None  # keep all columns\n",
    "\n",
    "def row_key(row):\n",
    "    parts = []\n",
    "    for c in key_cols:\n",
    "        parts.append(str(row[c]) if c in row and pd.notna(row[c]) else \"\")\n",
    "    return \"|\".join(parts)\n",
    "\n",
    "def assign_bucket(row):\n",
    "    # Deterministic hash in [0,1)\n",
    "    k = row_key(row) + \"|\" + seed + \"|\" + str(row[label_col])\n",
    "    h = hashlib.md5(k.encode(\"utf-8\")).hexdigest()\n",
    "    r = int(h, 16) / float(2**128)\n",
    "    # 0.0 to 0.7999 -> train, 0.8 to 0.8999 -> val, else test\n",
    "    if r < 0.8:\n",
    "        return \"train\"\n",
    "    elif r < 0.9:\n",
    "        return \"val\"\n",
    "    else:\n",
    "        return \"test\"\n",
    "\n",
    "# Counters\n",
    "n_train = n_val = n_test = 0\n",
    "\n",
    "for chunk in pd.read_csv(in_csv, chunksize=chunksize, usecols=usecols):\n",
    "    # Safety: if any key col missing in the file, create empty string column\n",
    "    for c in key_cols:\n",
    "        if c not in chunk.columns:\n",
    "            chunk[c] = \"\"\n",
    "\n",
    "    # Compute split per row\n",
    "    split = chunk.apply(assign_bucket, axis=1)\n",
    "\n",
    "    # Write each split\n",
    "    tmask = split == \"train\"\n",
    "    vmask = split == \"val\"\n",
    "    smask = split == \"test\"\n",
    "\n",
    "    if tmask.any():\n",
    "        chunk.loc[tmask].to_csv(train_csv, mode=\"w\" if first else \"a\", index=False, header=first)\n",
    "        n_train += int(tmask.sum())\n",
    "    if vmask.any():\n",
    "        chunk.loc[vmask].to_csv(val_csv, mode=\"w\" if first else \"a\", index=False, header=first)\n",
    "        n_val += int(vmask.sum())\n",
    "    if smask.any():\n",
    "        chunk.loc[smask].to_csv(test_csv, mode=\"w\" if first else \"a\", index=False, header=first)\n",
    "        n_test += int(smask.sum())\n",
    "\n",
    "    first = False  # headers written after first batch\n",
    "\n",
    "print(f\"Train: {n_train:,} rows -> {train_csv}\")\n",
    "print(f\"Val:   {n_val:,} rows -> {val_csv}\")\n",
    "print(f\"Test:  {n_test:,} rows -> {test_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and distribution:\n",
      "Ovary cancer cells: 16,036 (4.92%)\n",
      "Neurons: 16,019 (4.92%)\n",
      "Fibroblasts: 16,017 (4.92%)\n",
      "Myeloid cells: 16,011 (4.91%)\n",
      "Endothelial cells: 16,008 (4.91%)\n",
      "Cardiac muscle cells: 16,003 (4.91%)\n",
      "B cells: 15,999 (4.91%)\n",
      "Smooth muscle cells: 15,963 (4.90%)\n",
      "Epithelial cells: 15,941 (4.89%)\n",
      "Stem and progenitor cells: 15,934 (4.89%)\n",
      "T cells: 15,933 (4.89%)\n",
      "Colon cancer cells: 15,930 (4.89%)\n",
      "Erythrocytes: 15,925 (4.89%)\n",
      "Stromal cells: 15,898 (4.88%)\n",
      "Oligodendrocytes: 15,286 (4.69%)\n",
      "NK cells: 14,890 (4.57%)\n",
      "Skin cancer cells: 11,750 (3.61%)\n",
      "Mesangial cells: 10,851 (3.33%)\n",
      "Lung cancer cells: 9,638 (2.96%)\n",
      "Astrocytes: 8,946 (2.75%)\n",
      "Pericytes: 8,688 (2.67%)\n",
      "Pancreas cancer cells: 8,119 (2.49%)\n",
      "Skeletal muscle cells: 4,897 (1.50%)\n",
      "Schwann cells: 4,000 (1.23%)\n",
      "Microglia: 3,494 (1.07%)\n",
      "Liver cancer cells: 1,678 (0.51%)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/20pct_train.csv\"\n",
    "label_col = \"cell_type\"\n",
    "\n",
    "counts = Counter()\n",
    "total = 0\n",
    "\n",
    "# Stream the CSV in chunks\n",
    "for chunk in pd.read_csv(file_path, usecols=[label_col], chunksize=100_000):\n",
    "    vals = chunk[label_col]\n",
    "    counts.update(vals)\n",
    "    total += len(vals)\n",
    "\n",
    "# Print results\n",
    "print(\"Counts and distribution:\")\n",
    "for label, count in counts.most_common():\n",
    "    pct = count / total * 100\n",
    "    print(f\"{label}: {count:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mapping to /hpc/group/jilab/rz179/cellpt/combined/withBackground/class_to_idx_coarse.json\n",
      "{'Cancer cells': 0, 'Endothelial cells': 1, 'Epithelial cells': 2, 'Erythrocytes': 3, 'Glial cells': 4, 'Immune cells': 5, 'Muscle cells': 6, 'Neurons': 7, 'Stem and progenitor cells': 8, 'Stromal cells': 9}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "subset_csv = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled_no_bonecells_withCoarse_20pct.csv\"\n",
    "out_json   = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/class_to_idx_coarse.json\"\n",
    "label_col  = \"cell_type_coarse\"\n",
    "\n",
    "# Load subset\n",
    "df = pd.read_csv(subset_csv)\n",
    "\n",
    "# Get sorted unique classes\n",
    "classes = sorted(df[label_col].unique())\n",
    "\n",
    "# Build mapping {class_name: id}\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "# Save to JSON\n",
    "with open(out_json, \"w\") as f:\n",
    "    json.dump(class_to_idx, f, indent=2)\n",
    "\n",
    "print(\"Saved mapping to\", out_json)\n",
    "print(class_to_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the filtering process...\n",
      "This will:\n",
      "1. Read the original CSV in chunks\n",
      "2. Keep only rows where slide_id represents human tissues\n",
      "3. Remove all mouse tissue rows\n",
      "4. Save the filtered data to a new CSV\n",
      "\n",
      "Attempting filtering with different chunk sizes...\n",
      "\n",
      "Trying with chunk size: 5000\n",
      "Filtering human tissues from: /hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled_no_bonecells_withCoarse.csv\n",
      "Output will be saved to: /hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_human_only.csv\n",
      "Processing in chunks of 5000 rows...\n",
      "Processing chunk 1...\n",
      "  Created output file with 5000 rows\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 5,000 kept, 0 removed\n",
      "Processing chunk 2...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 10,000 kept, 0 removed\n",
      "Processing chunk 3...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 15,000 kept, 0 removed\n",
      "Processing chunk 4...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 20,000 kept, 0 removed\n",
      "Processing chunk 5...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 25,000 kept, 0 removed\n",
      "Processing chunk 6...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 30,000 kept, 0 removed\n",
      "Processing chunk 7...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 35,000 kept, 0 removed\n",
      "Processing chunk 8...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 40,000 kept, 0 removed\n",
      "Processing chunk 9...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 45,000 kept, 0 removed\n",
      "Processing chunk 10...\n",
      "  Added 3008 rows to output\n",
      "  Progress: 3008/5000 rows kept in this chunk\n",
      "  Running totals: 48,008 kept, 1,992 removed\n",
      "Processing chunk 11...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 48,008 kept, 6,992 removed\n",
      "Processing chunk 12...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 48,008 kept, 11,992 removed\n",
      "Processing chunk 13...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 48,008 kept, 16,992 removed\n",
      "Processing chunk 14...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 48,008 kept, 21,992 removed\n",
      "Processing chunk 15...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 48,008 kept, 26,992 removed\n",
      "Processing chunk 16...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 48,008 kept, 31,992 removed\n",
      "Processing chunk 17...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 48,008 kept, 36,992 removed\n",
      "Processing chunk 18...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 48,008 kept, 41,992 removed\n",
      "Processing chunk 19...\n",
      "  Added 2753 rows to output\n",
      "  Progress: 2753/5000 rows kept in this chunk\n",
      "  Running totals: 50,761 kept, 44,239 removed\n",
      "Processing chunk 20...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 55,761 kept, 44,239 removed\n",
      "Processing chunk 21...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 60,761 kept, 44,239 removed\n",
      "Processing chunk 22...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 65,761 kept, 44,239 removed\n",
      "Processing chunk 23...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 70,761 kept, 44,239 removed\n",
      "Processing chunk 24...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 75,761 kept, 44,239 removed\n",
      "Processing chunk 25...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 80,761 kept, 44,239 removed\n",
      "Processing chunk 26...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 85,761 kept, 44,239 removed\n",
      "Processing chunk 27...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 90,761 kept, 44,239 removed\n",
      "Processing chunk 28...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 95,761 kept, 44,239 removed\n",
      "Processing chunk 29...\n",
      "  Added 2950 rows to output\n",
      "  Progress: 2950/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 46,289 removed\n",
      "Processing chunk 30...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 51,289 removed\n",
      "Processing chunk 31...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 56,289 removed\n",
      "Processing chunk 32...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 61,289 removed\n",
      "Processing chunk 33...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 66,289 removed\n",
      "Processing chunk 34...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 71,289 removed\n",
      "Processing chunk 35...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 76,289 removed\n",
      "Processing chunk 36...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 81,289 removed\n",
      "Processing chunk 37...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 86,289 removed\n",
      "Processing chunk 38...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 91,289 removed\n",
      "Processing chunk 39...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 96,289 removed\n",
      "Processing chunk 40...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 101,289 removed\n",
      "Processing chunk 41...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 106,289 removed\n",
      "Processing chunk 42...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 111,289 removed\n",
      "Processing chunk 43...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 116,289 removed\n",
      "Processing chunk 44...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 121,289 removed\n",
      "Processing chunk 45...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 126,289 removed\n",
      "Processing chunk 46...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 131,289 removed\n",
      "Processing chunk 47...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 136,289 removed\n",
      "Processing chunk 48...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 141,289 removed\n",
      "Processing chunk 49...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 146,289 removed\n",
      "Processing chunk 50...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 151,289 removed\n",
      "Processing chunk 51...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 156,289 removed\n",
      "Processing chunk 52...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 161,289 removed\n",
      "Processing chunk 53...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 166,289 removed\n",
      "Processing chunk 54...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 98,711 kept, 171,289 removed\n",
      "Processing chunk 55...\n",
      "  Added 671 rows to output\n",
      "  Progress: 671/5000 rows kept in this chunk\n",
      "  Running totals: 99,382 kept, 175,618 removed\n",
      "Processing chunk 56...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 104,382 kept, 175,618 removed\n",
      "Processing chunk 57...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 109,382 kept, 175,618 removed\n",
      "Processing chunk 58...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 114,382 kept, 175,618 removed\n",
      "Processing chunk 59...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 119,382 kept, 175,618 removed\n",
      "Processing chunk 60...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 124,382 kept, 175,618 removed\n",
      "Processing chunk 61...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 129,382 kept, 175,618 removed\n",
      "Processing chunk 62...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 134,382 kept, 175,618 removed\n",
      "Processing chunk 63...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 139,382 kept, 175,618 removed\n",
      "Processing chunk 64...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 144,382 kept, 175,618 removed\n",
      "Processing chunk 65...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 149,382 kept, 175,618 removed\n",
      "Processing chunk 66...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 154,382 kept, 175,618 removed\n",
      "Processing chunk 67...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 159,382 kept, 175,618 removed\n",
      "Processing chunk 68...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 164,382 kept, 175,618 removed\n",
      "Processing chunk 69...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 169,382 kept, 175,618 removed\n",
      "Processing chunk 70...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 174,382 kept, 175,618 removed\n",
      "Processing chunk 71...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 179,382 kept, 175,618 removed\n",
      "Processing chunk 72...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 184,382 kept, 175,618 removed\n",
      "Processing chunk 73...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 189,382 kept, 175,618 removed\n",
      "Processing chunk 74...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 194,382 kept, 175,618 removed\n",
      "Processing chunk 75...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 199,382 kept, 175,618 removed\n",
      "Processing chunk 76...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 204,382 kept, 175,618 removed\n",
      "Processing chunk 77...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 209,382 kept, 175,618 removed\n",
      "Processing chunk 78...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 214,382 kept, 175,618 removed\n",
      "Processing chunk 79...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 219,382 kept, 175,618 removed\n",
      "Processing chunk 80...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 224,382 kept, 175,618 removed\n",
      "Processing chunk 81...\n",
      "  Added 2626 rows to output\n",
      "  Progress: 2626/5000 rows kept in this chunk\n",
      "  Running totals: 227,008 kept, 177,992 removed\n",
      "Processing chunk 82...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 227,008 kept, 182,992 removed\n",
      "Processing chunk 83...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 227,008 kept, 187,992 removed\n",
      "Processing chunk 84...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 227,008 kept, 192,992 removed\n",
      "Processing chunk 85...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 227,008 kept, 197,992 removed\n",
      "Processing chunk 86...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 227,008 kept, 202,992 removed\n",
      "Processing chunk 87...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 227,008 kept, 207,992 removed\n",
      "Processing chunk 88...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 227,008 kept, 212,992 removed\n",
      "Processing chunk 89...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 227,008 kept, 217,992 removed\n",
      "Processing chunk 90...\n",
      "  Added 1965 rows to output\n",
      "  Progress: 1965/5000 rows kept in this chunk\n",
      "  Running totals: 228,973 kept, 221,027 removed\n",
      "Processing chunk 91...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 233,973 kept, 221,027 removed\n",
      "Processing chunk 92...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 238,973 kept, 221,027 removed\n",
      "Processing chunk 93...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 243,973 kept, 221,027 removed\n",
      "Processing chunk 94...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 248,973 kept, 221,027 removed\n",
      "Processing chunk 95...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 253,973 kept, 221,027 removed\n",
      "Processing chunk 96...\n",
      "  Added 3733 rows to output\n",
      "  Progress: 3733/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 222,294 removed\n",
      "Processing chunk 97...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 227,294 removed\n",
      "Processing chunk 98...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 232,294 removed\n",
      "Processing chunk 99...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 237,294 removed\n",
      "Processing chunk 100...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 242,294 removed\n",
      "Processing chunk 101...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 247,294 removed\n",
      "Processing chunk 102...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 252,294 removed\n",
      "Processing chunk 103...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 257,294 removed\n",
      "Processing chunk 104...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 262,294 removed\n",
      "Processing chunk 105...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 267,294 removed\n",
      "Processing chunk 106...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 272,294 removed\n",
      "Processing chunk 107...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 277,294 removed\n",
      "Processing chunk 108...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 282,294 removed\n",
      "Processing chunk 109...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 287,294 removed\n",
      "Processing chunk 110...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 292,294 removed\n",
      "Processing chunk 111...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 297,294 removed\n",
      "Processing chunk 112...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 302,294 removed\n",
      "Processing chunk 113...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 307,294 removed\n",
      "Processing chunk 114...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 312,294 removed\n",
      "Processing chunk 115...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 317,294 removed\n",
      "Processing chunk 116...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 257,706 kept, 322,294 removed\n",
      "Processing chunk 117...\n",
      "  Added 4173 rows to output\n",
      "  Progress: 4173/5000 rows kept in this chunk\n",
      "  Running totals: 261,879 kept, 323,121 removed\n",
      "Processing chunk 118...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 266,879 kept, 323,121 removed\n",
      "Processing chunk 119...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 271,879 kept, 323,121 removed\n",
      "Processing chunk 120...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 276,879 kept, 323,121 removed\n",
      "Processing chunk 121...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 281,879 kept, 323,121 removed\n",
      "Processing chunk 122...\n",
      "  Added 2951 rows to output\n",
      "  Progress: 2951/5000 rows kept in this chunk\n",
      "  Running totals: 284,830 kept, 325,170 removed\n",
      "Processing chunk 123...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 284,830 kept, 330,170 removed\n",
      "Processing chunk 124...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 284,830 kept, 335,170 removed\n",
      "Processing chunk 125...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 284,830 kept, 340,170 removed\n",
      "Processing chunk 126...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 284,830 kept, 345,170 removed\n",
      "Processing chunk 127...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 284,830 kept, 350,170 removed\n",
      "Processing chunk 128...\n",
      "  Added 496 rows to output\n",
      "  Progress: 496/5000 rows kept in this chunk\n",
      "  Running totals: 285,326 kept, 354,674 removed\n",
      "Processing chunk 129...\n",
      "  Added 3625 rows to output\n",
      "  Progress: 3625/5000 rows kept in this chunk\n",
      "  Running totals: 288,951 kept, 356,049 removed\n",
      "Processing chunk 130...\n",
      "  Added 3725 rows to output\n",
      "  Progress: 3725/5000 rows kept in this chunk\n",
      "  Running totals: 292,676 kept, 357,324 removed\n",
      "Processing chunk 131...\n",
      "  Added 3671 rows to output\n",
      "  Progress: 3671/5000 rows kept in this chunk\n",
      "  Running totals: 296,347 kept, 358,653 removed\n",
      "Processing chunk 132...\n",
      "  Added 3642 rows to output\n",
      "  Progress: 3642/5000 rows kept in this chunk\n",
      "  Running totals: 299,989 kept, 360,011 removed\n",
      "Processing chunk 133...\n",
      "  Added 3638 rows to output\n",
      "  Progress: 3638/5000 rows kept in this chunk\n",
      "  Running totals: 303,627 kept, 361,373 removed\n",
      "Processing chunk 134...\n",
      "  Added 3650 rows to output\n",
      "  Progress: 3650/5000 rows kept in this chunk\n",
      "  Running totals: 307,277 kept, 362,723 removed\n",
      "Processing chunk 135...\n",
      "  Added 3695 rows to output\n",
      "  Progress: 3695/5000 rows kept in this chunk\n",
      "  Running totals: 310,972 kept, 364,028 removed\n",
      "Processing chunk 136...\n",
      "  Added 3662 rows to output\n",
      "  Progress: 3662/5000 rows kept in this chunk\n",
      "  Running totals: 314,634 kept, 365,366 removed\n",
      "Processing chunk 137...\n",
      "  Added 3641 rows to output\n",
      "  Progress: 3641/5000 rows kept in this chunk\n",
      "  Running totals: 318,275 kept, 366,725 removed\n",
      "Processing chunk 138...\n",
      "  Added 3640 rows to output\n",
      "  Progress: 3640/5000 rows kept in this chunk\n",
      "  Running totals: 321,915 kept, 368,085 removed\n",
      "Processing chunk 139...\n",
      "  Added 3677 rows to output\n",
      "  Progress: 3677/5000 rows kept in this chunk\n",
      "  Running totals: 325,592 kept, 369,408 removed\n",
      "Processing chunk 140...\n",
      "  Added 3625 rows to output\n",
      "  Progress: 3625/5000 rows kept in this chunk\n",
      "  Running totals: 329,217 kept, 370,783 removed\n",
      "Processing chunk 141...\n",
      "  Added 3667 rows to output\n",
      "  Progress: 3667/5000 rows kept in this chunk\n",
      "  Running totals: 332,884 kept, 372,116 removed\n",
      "Processing chunk 142...\n",
      "  Added 3676 rows to output\n",
      "  Progress: 3676/5000 rows kept in this chunk\n",
      "  Running totals: 336,560 kept, 373,440 removed\n",
      "Processing chunk 143...\n",
      "  Added 3653 rows to output\n",
      "  Progress: 3653/5000 rows kept in this chunk\n",
      "  Running totals: 340,213 kept, 374,787 removed\n",
      "Processing chunk 144...\n",
      "  Added 3669 rows to output\n",
      "  Progress: 3669/5000 rows kept in this chunk\n",
      "  Running totals: 343,882 kept, 376,118 removed\n",
      "Processing chunk 145...\n",
      "  Added 3688 rows to output\n",
      "  Progress: 3688/5000 rows kept in this chunk\n",
      "  Running totals: 347,570 kept, 377,430 removed\n",
      "Processing chunk 146...\n",
      "  Added 3663 rows to output\n",
      "  Progress: 3663/5000 rows kept in this chunk\n",
      "  Running totals: 351,233 kept, 378,767 removed\n",
      "Processing chunk 147...\n",
      "  Added 3689 rows to output\n",
      "  Progress: 3689/5000 rows kept in this chunk\n",
      "  Running totals: 354,922 kept, 380,078 removed\n",
      "Processing chunk 148...\n",
      "  Added 3589 rows to output\n",
      "  Progress: 3589/5000 rows kept in this chunk\n",
      "  Running totals: 358,511 kept, 381,489 removed\n",
      "Processing chunk 149...\n",
      "  Added 2825 rows to output\n",
      "  Progress: 2825/5000 rows kept in this chunk\n",
      "  Running totals: 361,336 kept, 383,664 removed\n",
      "Processing chunk 150...\n",
      "  Added 2880 rows to output\n",
      "  Progress: 2880/5000 rows kept in this chunk\n",
      "  Running totals: 364,216 kept, 385,784 removed\n",
      "Processing chunk 151...\n",
      "  Added 2896 rows to output\n",
      "  Progress: 2896/5000 rows kept in this chunk\n",
      "  Running totals: 367,112 kept, 387,888 removed\n",
      "Processing chunk 152...\n",
      "  Added 2879 rows to output\n",
      "  Progress: 2879/5000 rows kept in this chunk\n",
      "  Running totals: 369,991 kept, 390,009 removed\n",
      "Processing chunk 153...\n",
      "  Added 2786 rows to output\n",
      "  Progress: 2786/5000 rows kept in this chunk\n",
      "  Running totals: 372,777 kept, 392,223 removed\n",
      "Processing chunk 154...\n",
      "  Added 2797 rows to output\n",
      "  Progress: 2797/5000 rows kept in this chunk\n",
      "  Running totals: 375,574 kept, 394,426 removed\n",
      "Processing chunk 155...\n",
      "  Added 2795 rows to output\n",
      "  Progress: 2795/5000 rows kept in this chunk\n",
      "  Running totals: 378,369 kept, 396,631 removed\n",
      "Processing chunk 156...\n",
      "  Added 2773 rows to output\n",
      "  Progress: 2773/5000 rows kept in this chunk\n",
      "  Running totals: 381,142 kept, 398,858 removed\n",
      "Processing chunk 157...\n",
      "  Added 2852 rows to output\n",
      "  Progress: 2852/5000 rows kept in this chunk\n",
      "  Running totals: 383,994 kept, 401,006 removed\n",
      "Processing chunk 158...\n",
      "  Added 2849 rows to output\n",
      "  Progress: 2849/5000 rows kept in this chunk\n",
      "  Running totals: 386,843 kept, 403,157 removed\n",
      "Processing chunk 159...\n",
      "  Added 2767 rows to output\n",
      "  Progress: 2767/5000 rows kept in this chunk\n",
      "  Running totals: 389,610 kept, 405,390 removed\n",
      "Processing chunk 160...\n",
      "  Added 2800 rows to output\n",
      "  Progress: 2800/5000 rows kept in this chunk\n",
      "  Running totals: 392,410 kept, 407,590 removed\n",
      "Processing chunk 161...\n",
      "  Added 2796 rows to output\n",
      "  Progress: 2796/5000 rows kept in this chunk\n",
      "  Running totals: 395,206 kept, 409,794 removed\n",
      "Processing chunk 162...\n",
      "  Added 2785 rows to output\n",
      "  Progress: 2785/5000 rows kept in this chunk\n",
      "  Running totals: 397,991 kept, 412,009 removed\n",
      "Processing chunk 163...\n",
      "  Added 2844 rows to output\n",
      "  Progress: 2844/5000 rows kept in this chunk\n",
      "  Running totals: 400,835 kept, 414,165 removed\n",
      "Processing chunk 164...\n",
      "  Added 2834 rows to output\n",
      "  Progress: 2834/5000 rows kept in this chunk\n",
      "  Running totals: 403,669 kept, 416,331 removed\n",
      "Processing chunk 165...\n",
      "  Added 2805 rows to output\n",
      "  Progress: 2805/5000 rows kept in this chunk\n",
      "  Running totals: 406,474 kept, 418,526 removed\n",
      "Processing chunk 166...\n",
      "  Added 2828 rows to output\n",
      "  Progress: 2828/5000 rows kept in this chunk\n",
      "  Running totals: 409,302 kept, 420,698 removed\n",
      "Processing chunk 167...\n",
      "  Added 2805 rows to output\n",
      "  Progress: 2805/5000 rows kept in this chunk\n",
      "  Running totals: 412,107 kept, 422,893 removed\n",
      "Processing chunk 168...\n",
      "  Added 2984 rows to output\n",
      "  Progress: 2984/5000 rows kept in this chunk\n",
      "  Running totals: 415,091 kept, 424,909 removed\n",
      "Processing chunk 169...\n",
      "  Added 3799 rows to output\n",
      "  Progress: 3799/5000 rows kept in this chunk\n",
      "  Running totals: 418,890 kept, 426,110 removed\n",
      "Processing chunk 170...\n",
      "  Added 3778 rows to output\n",
      "  Progress: 3778/5000 rows kept in this chunk\n",
      "  Running totals: 422,668 kept, 427,332 removed\n",
      "Processing chunk 171...\n",
      "  Added 3761 rows to output\n",
      "  Progress: 3761/5000 rows kept in this chunk\n",
      "  Running totals: 426,429 kept, 428,571 removed\n",
      "Processing chunk 172...\n",
      "  Added 3776 rows to output\n",
      "  Progress: 3776/5000 rows kept in this chunk\n",
      "  Running totals: 430,205 kept, 429,795 removed\n",
      "Processing chunk 173...\n",
      "  Added 3761 rows to output\n",
      "  Progress: 3761/5000 rows kept in this chunk\n",
      "  Running totals: 433,966 kept, 431,034 removed\n",
      "Processing chunk 174...\n",
      "  Added 3761 rows to output\n",
      "  Progress: 3761/5000 rows kept in this chunk\n",
      "  Running totals: 437,727 kept, 432,273 removed\n",
      "Processing chunk 175...\n",
      "  Added 3802 rows to output\n",
      "  Progress: 3802/5000 rows kept in this chunk\n",
      "  Running totals: 441,529 kept, 433,471 removed\n",
      "Processing chunk 176...\n",
      "  Added 3801 rows to output\n",
      "  Progress: 3801/5000 rows kept in this chunk\n",
      "  Running totals: 445,330 kept, 434,670 removed\n",
      "Processing chunk 177...\n",
      "  Added 3793 rows to output\n",
      "  Progress: 3793/5000 rows kept in this chunk\n",
      "  Running totals: 449,123 kept, 435,877 removed\n",
      "Processing chunk 178...\n",
      "  Added 3762 rows to output\n",
      "  Progress: 3762/5000 rows kept in this chunk\n",
      "  Running totals: 452,885 kept, 437,115 removed\n",
      "Processing chunk 179...\n",
      "  Added 3774 rows to output\n",
      "  Progress: 3774/5000 rows kept in this chunk\n",
      "  Running totals: 456,659 kept, 438,341 removed\n",
      "Processing chunk 180...\n",
      "  Added 3781 rows to output\n",
      "  Progress: 3781/5000 rows kept in this chunk\n",
      "  Running totals: 460,440 kept, 439,560 removed\n",
      "Processing chunk 181...\n",
      "  Added 3780 rows to output\n",
      "  Progress: 3780/5000 rows kept in this chunk\n",
      "  Running totals: 464,220 kept, 440,780 removed\n",
      "Processing chunk 182...\n",
      "  Added 3710 rows to output\n",
      "  Progress: 3710/5000 rows kept in this chunk\n",
      "  Running totals: 467,930 kept, 442,070 removed\n",
      "Processing chunk 183...\n",
      "  Added 3791 rows to output\n",
      "  Progress: 3791/5000 rows kept in this chunk\n",
      "  Running totals: 471,721 kept, 443,279 removed\n",
      "Processing chunk 184...\n",
      "  Added 3755 rows to output\n",
      "  Progress: 3755/5000 rows kept in this chunk\n",
      "  Running totals: 475,476 kept, 444,524 removed\n",
      "Processing chunk 185...\n",
      "  Added 3731 rows to output\n",
      "  Progress: 3731/5000 rows kept in this chunk\n",
      "  Running totals: 479,207 kept, 445,793 removed\n",
      "Processing chunk 186...\n",
      "  Added 3732 rows to output\n",
      "  Progress: 3732/5000 rows kept in this chunk\n",
      "  Running totals: 482,939 kept, 447,061 removed\n",
      "Processing chunk 187...\n",
      "  Added 3757 rows to output\n",
      "  Progress: 3757/5000 rows kept in this chunk\n",
      "  Running totals: 486,696 kept, 448,304 removed\n",
      "Processing chunk 188...\n",
      "  Added 3724 rows to output\n",
      "  Progress: 3724/5000 rows kept in this chunk\n",
      "  Running totals: 490,420 kept, 449,580 removed\n",
      "Processing chunk 189...\n",
      "  Added 3393 rows to output\n",
      "  Progress: 3393/5000 rows kept in this chunk\n",
      "  Running totals: 493,813 kept, 451,187 removed\n",
      "Processing chunk 190...\n",
      "  Added 3358 rows to output\n",
      "  Progress: 3358/5000 rows kept in this chunk\n",
      "  Running totals: 497,171 kept, 452,829 removed\n",
      "Processing chunk 191...\n",
      "  Added 3294 rows to output\n",
      "  Progress: 3294/5000 rows kept in this chunk\n",
      "  Running totals: 500,465 kept, 454,535 removed\n",
      "Processing chunk 192...\n",
      "  Added 3336 rows to output\n",
      "  Progress: 3336/5000 rows kept in this chunk\n",
      "  Running totals: 503,801 kept, 456,199 removed\n",
      "Processing chunk 193...\n",
      "  Added 3313 rows to output\n",
      "  Progress: 3313/5000 rows kept in this chunk\n",
      "  Running totals: 507,114 kept, 457,886 removed\n",
      "Processing chunk 194...\n",
      "  Added 3323 rows to output\n",
      "  Progress: 3323/5000 rows kept in this chunk\n",
      "  Running totals: 510,437 kept, 459,563 removed\n",
      "Processing chunk 195...\n",
      "  Added 3299 rows to output\n",
      "  Progress: 3299/5000 rows kept in this chunk\n",
      "  Running totals: 513,736 kept, 461,264 removed\n",
      "Processing chunk 196...\n",
      "  Added 3323 rows to output\n",
      "  Progress: 3323/5000 rows kept in this chunk\n",
      "  Running totals: 517,059 kept, 462,941 removed\n",
      "Processing chunk 197...\n",
      "  Added 3334 rows to output\n",
      "  Progress: 3334/5000 rows kept in this chunk\n",
      "  Running totals: 520,393 kept, 464,607 removed\n",
      "Processing chunk 198...\n",
      "  Added 3287 rows to output\n",
      "  Progress: 3287/5000 rows kept in this chunk\n",
      "  Running totals: 523,680 kept, 466,320 removed\n",
      "Processing chunk 199...\n",
      "  Added 3317 rows to output\n",
      "  Progress: 3317/5000 rows kept in this chunk\n",
      "  Running totals: 526,997 kept, 468,003 removed\n",
      "Processing chunk 200...\n",
      "  Added 3359 rows to output\n",
      "  Progress: 3359/5000 rows kept in this chunk\n",
      "  Running totals: 530,356 kept, 469,644 removed\n",
      "Processing chunk 201...\n",
      "  Added 3289 rows to output\n",
      "  Progress: 3289/5000 rows kept in this chunk\n",
      "  Running totals: 533,645 kept, 471,355 removed\n",
      "Processing chunk 202...\n",
      "  Added 3342 rows to output\n",
      "  Progress: 3342/5000 rows kept in this chunk\n",
      "  Running totals: 536,987 kept, 473,013 removed\n",
      "Processing chunk 203...\n",
      "  Added 3305 rows to output\n",
      "  Progress: 3305/5000 rows kept in this chunk\n",
      "  Running totals: 540,292 kept, 474,708 removed\n",
      "Processing chunk 204...\n",
      "  Added 3377 rows to output\n",
      "  Progress: 3377/5000 rows kept in this chunk\n",
      "  Running totals: 543,669 kept, 476,331 removed\n",
      "Processing chunk 205...\n",
      "  Added 3315 rows to output\n",
      "  Progress: 3315/5000 rows kept in this chunk\n",
      "  Running totals: 546,984 kept, 478,016 removed\n",
      "Processing chunk 206...\n",
      "  Added 3301 rows to output\n",
      "  Progress: 3301/5000 rows kept in this chunk\n",
      "  Running totals: 550,285 kept, 479,715 removed\n",
      "Processing chunk 207...\n",
      "  Added 3295 rows to output\n",
      "  Progress: 3295/5000 rows kept in this chunk\n",
      "  Running totals: 553,580 kept, 481,420 removed\n",
      "Processing chunk 208...\n",
      "  Added 3302 rows to output\n",
      "  Progress: 3302/5000 rows kept in this chunk\n",
      "  Running totals: 556,882 kept, 483,118 removed\n",
      "Processing chunk 209...\n",
      "  Added 3063 rows to output\n",
      "  Progress: 3063/5000 rows kept in this chunk\n",
      "  Running totals: 559,945 kept, 485,055 removed\n",
      "Processing chunk 210...\n",
      "  Added 3155 rows to output\n",
      "  Progress: 3155/5000 rows kept in this chunk\n",
      "  Running totals: 563,100 kept, 486,900 removed\n",
      "Processing chunk 211...\n",
      "  Added 3094 rows to output\n",
      "  Progress: 3094/5000 rows kept in this chunk\n",
      "  Running totals: 566,194 kept, 488,806 removed\n",
      "Processing chunk 212...\n",
      "  Added 3055 rows to output\n",
      "  Progress: 3055/5000 rows kept in this chunk\n",
      "  Running totals: 569,249 kept, 490,751 removed\n",
      "Processing chunk 213...\n",
      "  Added 3095 rows to output\n",
      "  Progress: 3095/5000 rows kept in this chunk\n",
      "  Running totals: 572,344 kept, 492,656 removed\n",
      "Processing chunk 214...\n",
      "  Added 3068 rows to output\n",
      "  Progress: 3068/5000 rows kept in this chunk\n",
      "  Running totals: 575,412 kept, 494,588 removed\n",
      "Processing chunk 215...\n",
      "  Added 3109 rows to output\n",
      "  Progress: 3109/5000 rows kept in this chunk\n",
      "  Running totals: 578,521 kept, 496,479 removed\n",
      "Processing chunk 216...\n",
      "  Added 3088 rows to output\n",
      "  Progress: 3088/5000 rows kept in this chunk\n",
      "  Running totals: 581,609 kept, 498,391 removed\n",
      "Processing chunk 217...\n",
      "  Added 3075 rows to output\n",
      "  Progress: 3075/5000 rows kept in this chunk\n",
      "  Running totals: 584,684 kept, 500,316 removed\n",
      "Processing chunk 218...\n",
      "  Added 3106 rows to output\n",
      "  Progress: 3106/5000 rows kept in this chunk\n",
      "  Running totals: 587,790 kept, 502,210 removed\n",
      "Processing chunk 219...\n",
      "  Added 3071 rows to output\n",
      "  Progress: 3071/5000 rows kept in this chunk\n",
      "  Running totals: 590,861 kept, 504,139 removed\n",
      "Processing chunk 220...\n",
      "  Added 3042 rows to output\n",
      "  Progress: 3042/5000 rows kept in this chunk\n",
      "  Running totals: 593,903 kept, 506,097 removed\n",
      "Processing chunk 221...\n",
      "  Added 3100 rows to output\n",
      "  Progress: 3100/5000 rows kept in this chunk\n",
      "  Running totals: 597,003 kept, 507,997 removed\n",
      "Processing chunk 222...\n",
      "  Added 3082 rows to output\n",
      "  Progress: 3082/5000 rows kept in this chunk\n",
      "  Running totals: 600,085 kept, 509,915 removed\n",
      "Processing chunk 223...\n",
      "  Added 3116 rows to output\n",
      "  Progress: 3116/5000 rows kept in this chunk\n",
      "  Running totals: 603,201 kept, 511,799 removed\n",
      "Processing chunk 224...\n",
      "  Added 3168 rows to output\n",
      "  Progress: 3168/5000 rows kept in this chunk\n",
      "  Running totals: 606,369 kept, 513,631 removed\n",
      "Processing chunk 225...\n",
      "  Added 3050 rows to output\n",
      "  Progress: 3050/5000 rows kept in this chunk\n",
      "  Running totals: 609,419 kept, 515,581 removed\n",
      "Processing chunk 226...\n",
      "  Added 3093 rows to output\n",
      "  Progress: 3093/5000 rows kept in this chunk\n",
      "  Running totals: 612,512 kept, 517,488 removed\n",
      "Processing chunk 227...\n",
      "  Added 3130 rows to output\n",
      "  Progress: 3130/5000 rows kept in this chunk\n",
      "  Running totals: 615,642 kept, 519,358 removed\n",
      "Processing chunk 228...\n",
      "  Added 3383 rows to output\n",
      "  Progress: 3383/5000 rows kept in this chunk\n",
      "  Running totals: 619,025 kept, 520,975 removed\n",
      "Processing chunk 229...\n",
      "  Added 4494 rows to output\n",
      "  Progress: 4494/5000 rows kept in this chunk\n",
      "  Running totals: 623,519 kept, 521,481 removed\n",
      "Processing chunk 230...\n",
      "  Added 4500 rows to output\n",
      "  Progress: 4500/5000 rows kept in this chunk\n",
      "  Running totals: 628,019 kept, 521,981 removed\n",
      "Processing chunk 231...\n",
      "  Added 4492 rows to output\n",
      "  Progress: 4492/5000 rows kept in this chunk\n",
      "  Running totals: 632,511 kept, 522,489 removed\n",
      "Processing chunk 232...\n",
      "  Added 4493 rows to output\n",
      "  Progress: 4493/5000 rows kept in this chunk\n",
      "  Running totals: 637,004 kept, 522,996 removed\n",
      "Processing chunk 233...\n",
      "  Added 4477 rows to output\n",
      "  Progress: 4477/5000 rows kept in this chunk\n",
      "  Running totals: 641,481 kept, 523,519 removed\n",
      "Processing chunk 234...\n",
      "  Added 4460 rows to output\n",
      "  Progress: 4460/5000 rows kept in this chunk\n",
      "  Running totals: 645,941 kept, 524,059 removed\n",
      "Processing chunk 235...\n",
      "  Added 4467 rows to output\n",
      "  Progress: 4467/5000 rows kept in this chunk\n",
      "  Running totals: 650,408 kept, 524,592 removed\n",
      "Processing chunk 236...\n",
      "  Added 4497 rows to output\n",
      "  Progress: 4497/5000 rows kept in this chunk\n",
      "  Running totals: 654,905 kept, 525,095 removed\n",
      "Processing chunk 237...\n",
      "  Added 4524 rows to output\n",
      "  Progress: 4524/5000 rows kept in this chunk\n",
      "  Running totals: 659,429 kept, 525,571 removed\n",
      "Processing chunk 238...\n",
      "  Added 4465 rows to output\n",
      "  Progress: 4465/5000 rows kept in this chunk\n",
      "  Running totals: 663,894 kept, 526,106 removed\n",
      "Processing chunk 239...\n",
      "  Added 4478 rows to output\n",
      "  Progress: 4478/5000 rows kept in this chunk\n",
      "  Running totals: 668,372 kept, 526,628 removed\n",
      "Processing chunk 240...\n",
      "  Added 4483 rows to output\n",
      "  Progress: 4483/5000 rows kept in this chunk\n",
      "  Running totals: 672,855 kept, 527,145 removed\n",
      "Processing chunk 241...\n",
      "  Added 4495 rows to output\n",
      "  Progress: 4495/5000 rows kept in this chunk\n",
      "  Running totals: 677,350 kept, 527,650 removed\n",
      "Processing chunk 242...\n",
      "  Added 4526 rows to output\n",
      "  Progress: 4526/5000 rows kept in this chunk\n",
      "  Running totals: 681,876 kept, 528,124 removed\n",
      "Processing chunk 243...\n",
      "  Added 4461 rows to output\n",
      "  Progress: 4461/5000 rows kept in this chunk\n",
      "  Running totals: 686,337 kept, 528,663 removed\n",
      "Processing chunk 244...\n",
      "  Added 4498 rows to output\n",
      "  Progress: 4498/5000 rows kept in this chunk\n",
      "  Running totals: 690,835 kept, 529,165 removed\n",
      "Processing chunk 245...\n",
      "  Added 4505 rows to output\n",
      "  Progress: 4505/5000 rows kept in this chunk\n",
      "  Running totals: 695,340 kept, 529,660 removed\n",
      "Processing chunk 246...\n",
      "  Added 4459 rows to output\n",
      "  Progress: 4459/5000 rows kept in this chunk\n",
      "  Running totals: 699,799 kept, 530,201 removed\n",
      "Processing chunk 247...\n",
      "  Added 4528 rows to output\n",
      "  Progress: 4528/5000 rows kept in this chunk\n",
      "  Running totals: 704,327 kept, 530,673 removed\n",
      "Processing chunk 248...\n",
      "  Added 4455 rows to output\n",
      "  Progress: 4455/5000 rows kept in this chunk\n",
      "  Running totals: 708,782 kept, 531,218 removed\n",
      "Processing chunk 249...\n",
      "  Added 4147 rows to output\n",
      "  Progress: 4147/5000 rows kept in this chunk\n",
      "  Running totals: 712,929 kept, 532,071 removed\n",
      "Processing chunk 250...\n",
      "  Added 4149 rows to output\n",
      "  Progress: 4149/5000 rows kept in this chunk\n",
      "  Running totals: 717,078 kept, 532,922 removed\n",
      "Processing chunk 251...\n",
      "  Added 3791 rows to output\n",
      "  Progress: 3791/5000 rows kept in this chunk\n",
      "  Running totals: 720,869 kept, 534,131 removed\n",
      "Processing chunk 252...\n",
      "  Added 3704 rows to output\n",
      "  Progress: 3704/5000 rows kept in this chunk\n",
      "  Running totals: 724,573 kept, 535,427 removed\n",
      "Processing chunk 253...\n",
      "  Added 4184 rows to output\n",
      "  Progress: 4184/5000 rows kept in this chunk\n",
      "  Running totals: 728,757 kept, 536,243 removed\n",
      "Processing chunk 254...\n",
      "  Added 4155 rows to output\n",
      "  Progress: 4155/5000 rows kept in this chunk\n",
      "  Running totals: 732,912 kept, 537,088 removed\n",
      "Processing chunk 255...\n",
      "  Added 4185 rows to output\n",
      "  Progress: 4185/5000 rows kept in this chunk\n",
      "  Running totals: 737,097 kept, 537,903 removed\n",
      "Processing chunk 256...\n",
      "  Added 4127 rows to output\n",
      "  Progress: 4127/5000 rows kept in this chunk\n",
      "  Running totals: 741,224 kept, 538,776 removed\n",
      "Processing chunk 257...\n",
      "  Added 4192 rows to output\n",
      "  Progress: 4192/5000 rows kept in this chunk\n",
      "  Running totals: 745,416 kept, 539,584 removed\n",
      "Processing chunk 258...\n",
      "  Added 4211 rows to output\n",
      "  Progress: 4211/5000 rows kept in this chunk\n",
      "  Running totals: 749,627 kept, 540,373 removed\n",
      "Processing chunk 259...\n",
      "  Added 4208 rows to output\n",
      "  Progress: 4208/5000 rows kept in this chunk\n",
      "  Running totals: 753,835 kept, 541,165 removed\n",
      "Processing chunk 260...\n",
      "  Added 4143 rows to output\n",
      "  Progress: 4143/5000 rows kept in this chunk\n",
      "  Running totals: 757,978 kept, 542,022 removed\n",
      "Processing chunk 261...\n",
      "  Added 4187 rows to output\n",
      "  Progress: 4187/5000 rows kept in this chunk\n",
      "  Running totals: 762,165 kept, 542,835 removed\n",
      "Processing chunk 262...\n",
      "  Added 4152 rows to output\n",
      "  Progress: 4152/5000 rows kept in this chunk\n",
      "  Running totals: 766,317 kept, 543,683 removed\n",
      "Processing chunk 263...\n",
      "  Added 4188 rows to output\n",
      "  Progress: 4188/5000 rows kept in this chunk\n",
      "  Running totals: 770,505 kept, 544,495 removed\n",
      "Processing chunk 264...\n",
      "  Added 4167 rows to output\n",
      "  Progress: 4167/5000 rows kept in this chunk\n",
      "  Running totals: 774,672 kept, 545,328 removed\n",
      "Processing chunk 265...\n",
      "  Added 4176 rows to output\n",
      "  Progress: 4176/5000 rows kept in this chunk\n",
      "  Running totals: 778,848 kept, 546,152 removed\n",
      "Processing chunk 266...\n",
      "  Added 4164 rows to output\n",
      "  Progress: 4164/5000 rows kept in this chunk\n",
      "  Running totals: 783,012 kept, 546,988 removed\n",
      "Processing chunk 267...\n",
      "  Added 4191 rows to output\n",
      "  Progress: 4191/5000 rows kept in this chunk\n",
      "  Running totals: 787,203 kept, 547,797 removed\n",
      "Processing chunk 268...\n",
      "  Added 3621 rows to output\n",
      "  Progress: 3621/5000 rows kept in this chunk\n",
      "  Running totals: 790,824 kept, 549,176 removed\n",
      "Processing chunk 269...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 790,824 kept, 554,176 removed\n",
      "Processing chunk 270...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 790,824 kept, 559,176 removed\n",
      "Processing chunk 271...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 790,824 kept, 564,176 removed\n",
      "Processing chunk 272...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 790,824 kept, 569,176 removed\n",
      "Processing chunk 273...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 790,824 kept, 574,176 removed\n",
      "Processing chunk 274...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 790,824 kept, 579,176 removed\n",
      "Processing chunk 275...\n",
      "  Added 1731 rows to output\n",
      "  Progress: 1731/5000 rows kept in this chunk\n",
      "  Running totals: 792,555 kept, 582,445 removed\n",
      "Processing chunk 276...\n",
      "  Added 90 rows to output\n",
      "  Progress: 90/5000 rows kept in this chunk\n",
      "  Running totals: 792,645 kept, 587,355 removed\n",
      "Processing chunk 277...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 792,645 kept, 592,355 removed\n",
      "Processing chunk 278...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 792,645 kept, 597,355 removed\n",
      "Processing chunk 279...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 792,645 kept, 602,355 removed\n",
      "Processing chunk 280...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 792,645 kept, 607,355 removed\n",
      "Processing chunk 281...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 792,645 kept, 612,355 removed\n",
      "Processing chunk 282...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 792,645 kept, 617,355 removed\n",
      "Processing chunk 283...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 792,645 kept, 622,355 removed\n",
      "Processing chunk 284...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 792,645 kept, 627,355 removed\n",
      "Processing chunk 285...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 792,645 kept, 632,355 removed\n",
      "Processing chunk 286...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 792,645 kept, 637,355 removed\n",
      "Processing chunk 287...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 792,645 kept, 642,355 removed\n",
      "Processing chunk 288...\n",
      "  Added 149 rows to output\n",
      "  Progress: 149/5000 rows kept in this chunk\n",
      "  Running totals: 792,794 kept, 647,206 removed\n",
      "Processing chunk 289...\n",
      "  Added 1149 rows to output\n",
      "  Progress: 1149/5000 rows kept in this chunk\n",
      "  Running totals: 793,943 kept, 651,057 removed\n",
      "Processing chunk 290...\n",
      "  Added 1161 rows to output\n",
      "  Progress: 1161/5000 rows kept in this chunk\n",
      "  Running totals: 795,104 kept, 654,896 removed\n",
      "Processing chunk 291...\n",
      "  Added 1102 rows to output\n",
      "  Progress: 1102/5000 rows kept in this chunk\n",
      "  Running totals: 796,206 kept, 658,794 removed\n",
      "Processing chunk 292...\n",
      "  Added 1114 rows to output\n",
      "  Progress: 1114/5000 rows kept in this chunk\n",
      "  Running totals: 797,320 kept, 662,680 removed\n",
      "Processing chunk 293...\n",
      "  Added 1122 rows to output\n",
      "  Progress: 1122/5000 rows kept in this chunk\n",
      "  Running totals: 798,442 kept, 666,558 removed\n",
      "Processing chunk 294...\n",
      "  Added 1134 rows to output\n",
      "  Progress: 1134/5000 rows kept in this chunk\n",
      "  Running totals: 799,576 kept, 670,424 removed\n",
      "Processing chunk 295...\n",
      "  Added 1156 rows to output\n",
      "  Progress: 1156/5000 rows kept in this chunk\n",
      "  Running totals: 800,732 kept, 674,268 removed\n",
      "Processing chunk 296...\n",
      "  Added 1076 rows to output\n",
      "  Progress: 1076/5000 rows kept in this chunk\n",
      "  Running totals: 801,808 kept, 678,192 removed\n",
      "Processing chunk 297...\n",
      "  Added 1124 rows to output\n",
      "  Progress: 1124/5000 rows kept in this chunk\n",
      "  Running totals: 802,932 kept, 682,068 removed\n",
      "Processing chunk 298...\n",
      "  Added 1140 rows to output\n",
      "  Progress: 1140/5000 rows kept in this chunk\n",
      "  Running totals: 804,072 kept, 685,928 removed\n",
      "Processing chunk 299...\n",
      "  Added 1142 rows to output\n",
      "  Progress: 1142/5000 rows kept in this chunk\n",
      "  Running totals: 805,214 kept, 689,786 removed\n",
      "Processing chunk 300...\n",
      "  Added 1150 rows to output\n",
      "  Progress: 1150/5000 rows kept in this chunk\n",
      "  Running totals: 806,364 kept, 693,636 removed\n",
      "Processing chunk 301...\n",
      "  Added 1193 rows to output\n",
      "  Progress: 1193/5000 rows kept in this chunk\n",
      "  Running totals: 807,557 kept, 697,443 removed\n",
      "Processing chunk 302...\n",
      "  Added 1200 rows to output\n",
      "  Progress: 1200/5000 rows kept in this chunk\n",
      "  Running totals: 808,757 kept, 701,243 removed\n",
      "Processing chunk 303...\n",
      "  Added 1191 rows to output\n",
      "  Progress: 1191/5000 rows kept in this chunk\n",
      "  Running totals: 809,948 kept, 705,052 removed\n",
      "Processing chunk 304...\n",
      "  Added 1166 rows to output\n",
      "  Progress: 1166/5000 rows kept in this chunk\n",
      "  Running totals: 811,114 kept, 708,886 removed\n",
      "Processing chunk 305...\n",
      "  Added 2184 rows to output\n",
      "  Progress: 2184/5000 rows kept in this chunk\n",
      "  Running totals: 813,298 kept, 711,702 removed\n",
      "Processing chunk 306...\n",
      "  Added 1138 rows to output\n",
      "  Progress: 1138/5000 rows kept in this chunk\n",
      "  Running totals: 814,436 kept, 715,564 removed\n",
      "Processing chunk 307...\n",
      "  Added 1312 rows to output\n",
      "  Progress: 1312/5000 rows kept in this chunk\n",
      "  Running totals: 815,748 kept, 719,252 removed\n",
      "Processing chunk 308...\n",
      "  Added 976 rows to output\n",
      "  Progress: 976/5000 rows kept in this chunk\n",
      "  Running totals: 816,724 kept, 723,276 removed\n",
      "Processing chunk 309...\n",
      "  Added 4 rows to output\n",
      "  Progress: 4/5000 rows kept in this chunk\n",
      "  Running totals: 816,728 kept, 728,272 removed\n",
      "Processing chunk 310...\n",
      "  Added 12 rows to output\n",
      "  Progress: 12/5000 rows kept in this chunk\n",
      "  Running totals: 816,740 kept, 733,260 removed\n",
      "Processing chunk 311...\n",
      "  Added 12 rows to output\n",
      "  Progress: 12/5000 rows kept in this chunk\n",
      "  Running totals: 816,752 kept, 738,248 removed\n",
      "Processing chunk 312...\n",
      "  Added 16 rows to output\n",
      "  Progress: 16/5000 rows kept in this chunk\n",
      "  Running totals: 816,768 kept, 743,232 removed\n",
      "Processing chunk 313...\n",
      "  Added 1018 rows to output\n",
      "  Progress: 1018/5000 rows kept in this chunk\n",
      "  Running totals: 817,786 kept, 747,214 removed\n",
      "Processing chunk 314...\n",
      "  Added 119 rows to output\n",
      "  Progress: 119/5000 rows kept in this chunk\n",
      "  Running totals: 817,905 kept, 752,095 removed\n",
      "Processing chunk 315...\n",
      "  Added 14 rows to output\n",
      "  Progress: 14/5000 rows kept in this chunk\n",
      "  Running totals: 817,919 kept, 757,081 removed\n",
      "Processing chunk 316...\n",
      "  Added 12 rows to output\n",
      "  Progress: 12/5000 rows kept in this chunk\n",
      "  Running totals: 817,931 kept, 762,069 removed\n",
      "Processing chunk 317...\n",
      "  Added 13 rows to output\n",
      "  Progress: 13/5000 rows kept in this chunk\n",
      "  Running totals: 817,944 kept, 767,056 removed\n",
      "Processing chunk 318...\n",
      "  Added 11 rows to output\n",
      "  Progress: 11/5000 rows kept in this chunk\n",
      "  Running totals: 817,955 kept, 772,045 removed\n",
      "Processing chunk 319...\n",
      "  Added 15 rows to output\n",
      "  Progress: 15/5000 rows kept in this chunk\n",
      "  Running totals: 817,970 kept, 777,030 removed\n",
      "Processing chunk 320...\n",
      "  Added 17 rows to output\n",
      "  Progress: 17/5000 rows kept in this chunk\n",
      "  Running totals: 817,987 kept, 782,013 removed\n",
      "Processing chunk 321...\n",
      "  Added 13 rows to output\n",
      "  Progress: 13/5000 rows kept in this chunk\n",
      "  Running totals: 818,000 kept, 787,000 removed\n",
      "Processing chunk 322...\n",
      "  Added 12 rows to output\n",
      "  Progress: 12/5000 rows kept in this chunk\n",
      "  Running totals: 818,012 kept, 791,988 removed\n",
      "Processing chunk 323...\n",
      "  Added 11 rows to output\n",
      "  Progress: 11/5000 rows kept in this chunk\n",
      "  Running totals: 818,023 kept, 796,977 removed\n",
      "Processing chunk 324...\n",
      "  Added 11 rows to output\n",
      "  Progress: 11/5000 rows kept in this chunk\n",
      "  Running totals: 818,034 kept, 801,966 removed\n",
      "Processing chunk 325...\n",
      "  Added 12 rows to output\n",
      "  Progress: 12/5000 rows kept in this chunk\n",
      "  Running totals: 818,046 kept, 806,954 removed\n",
      "Processing chunk 326...\n",
      "  Added 13 rows to output\n",
      "  Progress: 13/5000 rows kept in this chunk\n",
      "  Running totals: 818,059 kept, 811,941 removed\n",
      "Processing chunk 327...\n",
      "  Added 8 rows to output\n",
      "  Progress: 8/5000 rows kept in this chunk\n",
      "  Running totals: 818,067 kept, 816,933 removed\n",
      "Processing chunk 328...\n",
      "  Added 19 rows to output\n",
      "  Progress: 19/5000 rows kept in this chunk\n",
      "  Running totals: 818,086 kept, 821,914 removed\n",
      "Processing chunk 329...\n",
      "  Added 1791 rows to output\n",
      "  Progress: 1791/5000 rows kept in this chunk\n",
      "  Running totals: 819,877 kept, 825,123 removed\n",
      "Processing chunk 330...\n",
      "  Added 1761 rows to output\n",
      "  Progress: 1761/5000 rows kept in this chunk\n",
      "  Running totals: 821,638 kept, 828,362 removed\n",
      "Processing chunk 331...\n",
      "  Added 1571 rows to output\n",
      "  Progress: 1571/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 831,791 removed\n",
      "Processing chunk 332...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 836,791 removed\n",
      "Processing chunk 333...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 841,791 removed\n",
      "Processing chunk 334...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 846,791 removed\n",
      "Processing chunk 335...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 851,791 removed\n",
      "Processing chunk 336...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 856,791 removed\n",
      "Processing chunk 337...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 861,791 removed\n",
      "Processing chunk 338...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 866,791 removed\n",
      "Processing chunk 339...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 871,791 removed\n",
      "Processing chunk 340...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 876,791 removed\n",
      "Processing chunk 341...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 881,791 removed\n",
      "Processing chunk 342...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 886,791 removed\n",
      "Processing chunk 343...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 891,791 removed\n",
      "Processing chunk 344...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 896,791 removed\n",
      "Processing chunk 345...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 901,791 removed\n",
      "Processing chunk 346...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 906,791 removed\n",
      "Processing chunk 347...\n",
      "  Added 0 rows to output\n",
      "  Progress: 0/5000 rows kept in this chunk\n",
      "  Running totals: 823,209 kept, 911,791 removed\n",
      "Processing chunk 348...\n",
      "  Added 679 rows to output\n",
      "  Progress: 679/5000 rows kept in this chunk\n",
      "  Running totals: 823,888 kept, 916,112 removed\n",
      "Processing chunk 349...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 828,888 kept, 916,112 removed\n",
      "Processing chunk 350...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 833,888 kept, 916,112 removed\n",
      "Processing chunk 351...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 838,888 kept, 916,112 removed\n",
      "Processing chunk 352...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 843,888 kept, 916,112 removed\n",
      "Processing chunk 353...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 848,888 kept, 916,112 removed\n",
      "Processing chunk 354...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 853,888 kept, 916,112 removed\n",
      "Processing chunk 355...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 858,888 kept, 916,112 removed\n",
      "Processing chunk 356...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 863,888 kept, 916,112 removed\n",
      "Processing chunk 357...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 868,888 kept, 916,112 removed\n",
      "Processing chunk 358...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 873,888 kept, 916,112 removed\n",
      "Processing chunk 359...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 878,888 kept, 916,112 removed\n",
      "Processing chunk 360...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 883,888 kept, 916,112 removed\n",
      "Processing chunk 361...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 888,888 kept, 916,112 removed\n",
      "Processing chunk 362...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 893,888 kept, 916,112 removed\n",
      "Processing chunk 363...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 898,888 kept, 916,112 removed\n",
      "Processing chunk 364...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 903,888 kept, 916,112 removed\n",
      "Processing chunk 365...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 908,888 kept, 916,112 removed\n",
      "Processing chunk 366...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 913,888 kept, 916,112 removed\n",
      "Processing chunk 367...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 918,888 kept, 916,112 removed\n",
      "Processing chunk 368...\n",
      "  Added 4862 rows to output\n",
      "  Progress: 4862/5000 rows kept in this chunk\n",
      "  Running totals: 923,750 kept, 916,250 removed\n",
      "Processing chunk 369...\n",
      "  Added 3833 rows to output\n",
      "  Progress: 3833/5000 rows kept in this chunk\n",
      "  Running totals: 927,583 kept, 917,417 removed\n",
      "Processing chunk 370...\n",
      "  Added 3882 rows to output\n",
      "  Progress: 3882/5000 rows kept in this chunk\n",
      "  Running totals: 931,465 kept, 918,535 removed\n",
      "Processing chunk 371...\n",
      "  Added 3882 rows to output\n",
      "  Progress: 3882/5000 rows kept in this chunk\n",
      "  Running totals: 935,347 kept, 919,653 removed\n",
      "Processing chunk 372...\n",
      "  Added 3909 rows to output\n",
      "  Progress: 3909/5000 rows kept in this chunk\n",
      "  Running totals: 939,256 kept, 920,744 removed\n",
      "Processing chunk 373...\n",
      "  Added 3876 rows to output\n",
      "  Progress: 3876/5000 rows kept in this chunk\n",
      "  Running totals: 943,132 kept, 921,868 removed\n",
      "Processing chunk 374...\n",
      "  Added 3823 rows to output\n",
      "  Progress: 3823/5000 rows kept in this chunk\n",
      "  Running totals: 946,955 kept, 923,045 removed\n",
      "Processing chunk 375...\n",
      "  Added 3817 rows to output\n",
      "  Progress: 3817/5000 rows kept in this chunk\n",
      "  Running totals: 950,772 kept, 924,228 removed\n",
      "Processing chunk 376...\n",
      "  Added 3899 rows to output\n",
      "  Progress: 3899/5000 rows kept in this chunk\n",
      "  Running totals: 954,671 kept, 925,329 removed\n",
      "Processing chunk 377...\n",
      "  Added 3927 rows to output\n",
      "  Progress: 3927/5000 rows kept in this chunk\n",
      "  Running totals: 958,598 kept, 926,402 removed\n",
      "Processing chunk 378...\n",
      "  Added 3850 rows to output\n",
      "  Progress: 3850/5000 rows kept in this chunk\n",
      "  Running totals: 962,448 kept, 927,552 removed\n",
      "Processing chunk 379...\n",
      "  Added 3817 rows to output\n",
      "  Progress: 3817/5000 rows kept in this chunk\n",
      "  Running totals: 966,265 kept, 928,735 removed\n",
      "Processing chunk 380...\n",
      "  Added 3846 rows to output\n",
      "  Progress: 3846/5000 rows kept in this chunk\n",
      "  Running totals: 970,111 kept, 929,889 removed\n",
      "Processing chunk 381...\n",
      "  Added 3828 rows to output\n",
      "  Progress: 3828/5000 rows kept in this chunk\n",
      "  Running totals: 973,939 kept, 931,061 removed\n",
      "Processing chunk 382...\n",
      "  Added 3891 rows to output\n",
      "  Progress: 3891/5000 rows kept in this chunk\n",
      "  Running totals: 977,830 kept, 932,170 removed\n",
      "Processing chunk 383...\n",
      "  Added 3855 rows to output\n",
      "  Progress: 3855/5000 rows kept in this chunk\n",
      "  Running totals: 981,685 kept, 933,315 removed\n",
      "Processing chunk 384...\n",
      "  Added 3857 rows to output\n",
      "  Progress: 3857/5000 rows kept in this chunk\n",
      "  Running totals: 985,542 kept, 934,458 removed\n",
      "Processing chunk 385...\n",
      "  Added 3870 rows to output\n",
      "  Progress: 3870/5000 rows kept in this chunk\n",
      "  Running totals: 989,412 kept, 935,588 removed\n",
      "Processing chunk 386...\n",
      "  Added 3799 rows to output\n",
      "  Progress: 3799/5000 rows kept in this chunk\n",
      "  Running totals: 993,211 kept, 936,789 removed\n",
      "Processing chunk 387...\n",
      "  Added 3800 rows to output\n",
      "  Progress: 3800/5000 rows kept in this chunk\n",
      "  Running totals: 997,011 kept, 937,989 removed\n",
      "Processing chunk 388...\n",
      "  Added 4024 rows to output\n",
      "  Progress: 4024/5000 rows kept in this chunk\n",
      "  Running totals: 1,001,035 kept, 938,965 removed\n",
      "Processing chunk 389...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,006,035 kept, 938,965 removed\n",
      "Processing chunk 390...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,011,035 kept, 938,965 removed\n",
      "Processing chunk 391...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,016,035 kept, 938,965 removed\n",
      "Processing chunk 392...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,021,035 kept, 938,965 removed\n",
      "Processing chunk 393...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,026,035 kept, 938,965 removed\n",
      "Processing chunk 394...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,031,035 kept, 938,965 removed\n",
      "Processing chunk 395...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,036,035 kept, 938,965 removed\n",
      "Processing chunk 396...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,041,035 kept, 938,965 removed\n",
      "Processing chunk 397...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,046,035 kept, 938,965 removed\n",
      "Processing chunk 398...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,051,035 kept, 938,965 removed\n",
      "Processing chunk 399...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,056,035 kept, 938,965 removed\n",
      "Processing chunk 400...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,061,035 kept, 938,965 removed\n",
      "Processing chunk 401...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,066,035 kept, 938,965 removed\n",
      "Processing chunk 402...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,071,035 kept, 938,965 removed\n",
      "Processing chunk 403...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,076,035 kept, 938,965 removed\n",
      "Processing chunk 404...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,081,035 kept, 938,965 removed\n",
      "Processing chunk 405...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,086,035 kept, 938,965 removed\n",
      "Processing chunk 406...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,091,035 kept, 938,965 removed\n",
      "Processing chunk 407...\n",
      "  Added 5000 rows to output\n",
      "  Progress: 5000/5000 rows kept in this chunk\n",
      "  Running totals: 1,096,035 kept, 938,965 removed\n",
      "Processing chunk 408...\n",
      "  Added 4321 rows to output\n",
      "  Progress: 4321/4321 rows kept in this chunk\n",
      "  Running totals: 1,100,356 kept, 938,965 removed\n",
      "\n",
      "==================================================\n",
      "FILTERING COMPLETE!\n",
      "==================================================\n",
      "Total rows processed: 2,039,321\n",
      "Human rows kept: 1,100,356\n",
      "Mouse rows removed: 938,965\n",
      "Percentage kept: 54.0%\n",
      "Output saved to: /hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_human_only.csv\n",
      "\n",
      " Filtering completed successfully!\n",
      "Your human-only dataset is ready at: /hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_human_only.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def is_human_tissue(slide_id):\n",
    "    \"\"\"\n",
    "    Determine if a slide_id represents human tissue.\n",
    "    Returns True for human, False for mouse.\n",
    "    \"\"\"\n",
    "    slide_id_lower = slide_id.lower()\n",
    "    \n",
    "    # Mouse identifiers to exclude\n",
    "    mouse_patterns = [\n",
    "        'mouse',           # Contains \"mouse\"\n",
    "        '_m',             # Starts with m after underscore (like Xenium_V1_mFemur)\n",
    "        'xenium_v1_m',    # Specific pattern for mouse samples\n",
    "        'pup',            # Mouse pup samples\n",
    "        'tgcrnd8',        # Transgenic mouse model\n",
    "        'wildtype'        # Wildtype mouse samples\n",
    "    ]\n",
    "    \n",
    "    # Check if any mouse pattern is found\n",
    "    for pattern in mouse_patterns:\n",
    "        if pattern in slide_id_lower:\n",
    "            return False\n",
    "    \n",
    "    # Additional specific checks\n",
    "    if slide_id_lower.startswith('xenium_prime_mouse'):\n",
    "        return False\n",
    "        \n",
    "    # If none of the mouse patterns match, assume it's human\n",
    "    return True\n",
    "\n",
    "def filter_human_tissues(input_file, output_file, chunksize=5000):\n",
    "    \"\"\"\n",
    "    Filter CSV to keep only human tissues, processing in chunks.\n",
    "    \"\"\"\n",
    "    print(f\"Filtering human tissues from: {input_file}\")\n",
    "    print(f\"Output will be saved to: {output_file}\")\n",
    "    print(f\"Processing in chunks of {chunksize} rows...\")\n",
    "    \n",
    "    first_chunk = True\n",
    "    total_rows_processed = 0\n",
    "    human_rows_kept = 0\n",
    "    mouse_rows_removed = 0\n",
    "    \n",
    "    try:\n",
    "        for chunk_num, chunk in enumerate(pd.read_csv(input_file, chunksize=chunksize), 1):\n",
    "            print(f\"Processing chunk {chunk_num}...\")\n",
    "            \n",
    "            # Filter for human tissues\n",
    "            human_mask = chunk['slide_id'].apply(is_human_tissue)\n",
    "            human_chunk = chunk[human_mask]\n",
    "            \n",
    "            # Update counters\n",
    "            total_rows_processed += len(chunk)\n",
    "            human_rows_kept += len(human_chunk)\n",
    "            mouse_rows_removed += len(chunk) - len(human_chunk)\n",
    "            \n",
    "            # Write to output file\n",
    "            if first_chunk:\n",
    "                # Write header for first chunk\n",
    "                human_chunk.to_csv(output_file, index=False, mode='w')\n",
    "                first_chunk = False\n",
    "                print(f\"  Created output file with {len(human_chunk)} rows\")\n",
    "            else:\n",
    "                # Append without header for subsequent chunks\n",
    "                human_chunk.to_csv(output_file, index=False, mode='a', header=False)\n",
    "                print(f\"  Added {len(human_chunk)} rows to output\")\n",
    "            \n",
    "            print(f\"  Progress: {len(human_chunk)}/{len(chunk)} rows kept in this chunk\")\n",
    "            print(f\"  Running totals: {human_rows_kept:,} kept, {mouse_rows_removed:,} removed\")\n",
    "            \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"FILTERING COMPLETE!\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Total rows processed: {total_rows_processed:,}\")\n",
    "        print(f\"Human rows kept: {human_rows_kept:,}\")\n",
    "        print(f\"Mouse rows removed: {mouse_rows_removed:,}\")\n",
    "        print(f\"Percentage kept: {(human_rows_kept/total_rows_processed)*100:.1f}%\")\n",
    "        print(f\"Output saved to: {output_file}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during filtering: {e}\")\n",
    "        return False\n",
    "\n",
    "# File paths\n",
    "input_file = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_downsampled_no_bonecells_withCoarse.csv\"\n",
    "output_file = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_human_only.csv\"  # Save to work directory\n",
    "\n",
    "print(\"Starting the filtering process...\")\n",
    "print(\"This will:\")\n",
    "print(\"1. Read the original CSV in chunks\")\n",
    "print(\"2. Keep only rows where slide_id represents human tissues\")\n",
    "print(\"3. Remove all mouse tissue rows\")\n",
    "print(\"4. Save the filtered data to a new CSV\")\n",
    "print()\n",
    "\n",
    "# Try with progressively smaller chunk sizes if needed\n",
    "chunk_sizes = [5000, 1000, 100]\n",
    "\n",
    "print(\"Attempting filtering with different chunk sizes...\")\n",
    "\n",
    "success = False\n",
    "for chunk_size in chunk_sizes:\n",
    "    print(f\"\\nTrying with chunk size: {chunk_size}\")\n",
    "    try:\n",
    "        success = filter_human_tissues(input_file, output_file, chunksize=chunk_size)\n",
    "        if success:\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"Failed with chunk size {chunk_size}: {e}\")\n",
    "        continue\n",
    "\n",
    "if success:\n",
    "    print(\"\\n Filtering completed successfully!\")\n",
    "    print(f\"Your human-only dataset is ready at: {output_file}\")\n",
    "else:\n",
    "    print(\"\\n All Python methods failed.\")\n",
    "    print(\"Trying command-line approach instead...\")\n",
    "    \n",
    "    # Command line fallback\n",
    "    print(\"\\nCOMMAND LINE FALLBACK:\")\n",
    "    print(\"Run these commands in your terminal:\")\n",
    "    print(f\"cd /work/rz179\")\n",
    "    print(f\"# First, find the slide_id column number:\")\n",
    "    print(f\"head -1 '{input_file}' | tr ',' '\\\\n' | nl\")\n",
    "    print(f\"# Then filter (replace X with slide_id column number):\")\n",
    "    print(f\"awk -F',' 'NR==1 {{print}} NR>1 && $X !~ /mouse|Mouse|pup|TgCRND8|wildtype|mFemur/ {{print}}' '{input_file}' > combined_meta_human_only.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove tail classes from HUMAN ONLY, that has less than 5000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class policy summary: drop=2, keep_all=20, cap=0\n",
      "Pass 2 done. Total rows seen 1,100,356. Wrote keep_all 1,097,184. Sharded 0. Dropped 3,172.\n",
      "Done. Final file: /hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_human_only_20to1.csv\n",
      "Rows appended from shards 0. Now you can remove temp dir if you want: /hpc/group/jilab/rz179/cellpt/combined/withBackground/tmp_celltype_shards\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Inputs\n",
    "in_csv = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_human_only.csv\"\n",
    "out_csv = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_human_only_20to1.csv\"\n",
    "tmp_dir = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/tmp_celltype_shards\"\n",
    "label_col = \"cell_type\"\n",
    "keep_cols = [\n",
    "    \"slide_id\", \"cell_type_coarse\", \"cell_type\",\n",
    "    \"raw_img_path\", \"mask_target_img_path\", \"mask_context_img_path\",\n",
    "    \"nucleus_id\", \"cell_id\",\n",
    "]\n",
    "chunksize = 200_000\n",
    "cap = 100_000\n",
    "min_keep = 5_000\n",
    "seed = 23\n",
    "random.seed(seed)\n",
    "\n",
    "Path(tmp_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Pass 1. Count classes\n",
    "counts = Counter()\n",
    "for chunk in pd.read_csv(in_csv, usecols=[label_col], chunksize=chunksize):\n",
    "    counts.update(chunk[label_col])\n",
    "\n",
    "# Decide policy\n",
    "policy = {}\n",
    "for cls, n in counts.items():\n",
    "    if n < min_keep:\n",
    "        policy[cls] = (\"drop\", 0)\n",
    "    elif n <= cap:\n",
    "        policy[cls] = (\"keep_all\", n)\n",
    "    else:\n",
    "        policy[cls] = (\"cap\", cap)\n",
    "\n",
    "num_drop = sum(1 for v in policy.values() if v[0] == \"drop\")\n",
    "num_keep_all = sum(1 for v in policy.values() if v[0] == \"keep_all\")\n",
    "num_cap = sum(1 for v in policy.values() if v[0] == \"cap\")\n",
    "print(f\"Class policy summary: drop={num_drop}, keep_all={num_keep_all}, cap={num_cap}\")\n",
    "\n",
    "# Prepare final file with header\n",
    "with open(out_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(keep_cols)\n",
    "\n",
    "# Helper to make safe shard file names\n",
    "def shard_path_for_class(cls_name: str) -> Path:\n",
    "    safe = \"\".join(ch if ch.isalnum() or ch in \"._-\" else \"_\" for ch in str(cls_name))\n",
    "    return Path(tmp_dir) / f\"class_{safe}.csv\"\n",
    "\n",
    "# Pass 2. Stream and write\n",
    "# For keep_all classes, write directly to final\n",
    "# For cap classes, write into class shard files\n",
    "shard_writers = {}\n",
    "shard_files = {}\n",
    "\n",
    "def get_shard_writer(cls):\n",
    "    if cls in shard_writers:\n",
    "        return shard_writers[cls]\n",
    "    p = shard_path_for_class(cls)\n",
    "    f = open(p, \"w\", newline=\"\")\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(keep_cols)\n",
    "    shard_files[cls] = f\n",
    "    shard_writers[cls] = w\n",
    "    return w\n",
    "\n",
    "usecols = list(set(keep_cols + [label_col]))\n",
    "total_rows = 0\n",
    "kept_direct = 0\n",
    "sharded = 0\n",
    "dropped = 0\n",
    "\n",
    "with open(out_csv, \"a\", newline=\"\") as f_out:\n",
    "    out_writer = csv.writer(f_out)\n",
    "    for chunk in pd.read_csv(in_csv, usecols=usecols, chunksize=chunksize):\n",
    "        total_rows += len(chunk)\n",
    "        # restrict to the columns we want to write\n",
    "        chunk = chunk[keep_cols]\n",
    "        for row in chunk.itertuples(index=False, name=None):\n",
    "            # row order matches keep_cols\n",
    "            cls = row[keep_cols.index(label_col)]\n",
    "            act, k = policy.get(cls, (\"drop\", 0))\n",
    "\n",
    "            if act == \"drop\":\n",
    "                dropped += 1\n",
    "                continue\n",
    "            if act == \"keep_all\":\n",
    "                out_writer.writerow(row)\n",
    "                kept_direct += 1\n",
    "            else:\n",
    "                # cap policy\n",
    "                w = get_shard_writer(cls)\n",
    "                w.writerow(row)\n",
    "                sharded += 1\n",
    "\n",
    "# Close all shard files\n",
    "for f in shard_files.values():\n",
    "    f.close()\n",
    "\n",
    "print(f\"Pass 2 done. Total rows seen {total_rows:,}. Wrote keep_all {kept_direct:,}. Sharded {sharded:,}. Dropped {dropped:,}.\")\n",
    "\n",
    "# Pass 3. For each capped class shard, do reservoir sample of size cap, append to final\n",
    "def reservoir_sample_from_csv(csv_path: Path, k: int, header=True):\n",
    "    \"\"\"Return a list of up to k rows from csv_path using Algorithm R.\"\"\"\n",
    "    sample = []\n",
    "    with open(csv_path, \"r\", newline=\"\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        if header:\n",
    "            next(reader, None)\n",
    "        seen = 0\n",
    "        for row in reader:\n",
    "            seen += 1\n",
    "            if len(sample) < k:\n",
    "                sample.append(row)\n",
    "            else:\n",
    "                j = random.randint(1, seen)\n",
    "                if j <= k:\n",
    "                    sample[j - 1] = row\n",
    "    return sample\n",
    "\n",
    "added_from_shards = 0\n",
    "with open(out_csv, \"a\", newline=\"\") as f_out:\n",
    "    out_writer = csv.writer(f_out)\n",
    "    for cls, (act, k) in policy.items():\n",
    "        if act != \"cap\":\n",
    "            continue\n",
    "        shard_path = shard_path_for_class(cls)\n",
    "        if not shard_path.exists():\n",
    "            # No rows ended up in this shard. Skip.\n",
    "            continue\n",
    "        # For safety, compute target k as min(cap, actual rows)\n",
    "        # This also protects against off by ones\n",
    "        # Count rows quickly\n",
    "        with open(shard_path, \"r\") as f:\n",
    "            rows_in_file = sum(1 for _ in f) - 1  # minus header\n",
    "        target_k = min(k, rows_in_file)\n",
    "        if target_k <= 0:\n",
    "            continue\n",
    "        sample_rows = reservoir_sample_from_csv(shard_path, target_k, header=True)\n",
    "        out_writer.writerows(sample_rows)\n",
    "        added_from_shards += len(sample_rows)\n",
    "        print(f\"Appended {len(sample_rows):,} rows for class {cls}\")\n",
    "\n",
    "print(f\"Done. Final file: {out_csv}\")\n",
    "print(f\"Rows appended from shards {added_from_shards:,}. Now you can remove temp dir if you want: {tmp_dir}\")\n",
    "\n",
    "# Optional cleanup\n",
    "# shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split for full human only dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 877,217 rows -> /hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/full_train.csv\n",
      "Val:   109,864 rows -> /hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/full_val.csv\n",
      "Test:  110,103 rows -> /hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/full_test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "\n",
    "in_csv   = \"/hpc/group/jilab/rz179/cellpt/combined/withBackground/combined_meta_human_only_20to1.csv\"  \n",
    "train_csv = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/full_train.csv\"\n",
    "val_csv   = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/full_val.csv\"\n",
    "test_csv  = \"/hpc/group/jilab/rz179/cellpt/combined/54s/semi_balanced/full_test.csv\"\n",
    "\n",
    "label_col = \"cell_type\"\n",
    "# Columns to build a stable, unique key per row. Adjust if needed.\n",
    "key_cols = [\"slide_id\", \"nucleus_id\", \"cell_id\"]\n",
    "seed = \"23\"  # string is fine\n",
    "\n",
    "chunksize = 200_000\n",
    "first = True\n",
    "\n",
    "# Make sure parents exist\n",
    "os.makedirs(os.path.dirname(train_csv), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(val_csv), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(test_csv), exist_ok=True)\n",
    "\n",
    "# We only need the columns we will write\n",
    "# If you want to keep all columns, set usecols=None\n",
    "usecols = None  # keep all columns\n",
    "\n",
    "def row_key(row):\n",
    "    parts = []\n",
    "    for c in key_cols:\n",
    "        parts.append(str(row[c]) if c in row and pd.notna(row[c]) else \"\")\n",
    "    return \"|\".join(parts)\n",
    "\n",
    "def assign_bucket(row):\n",
    "    # Deterministic hash in [0,1)\n",
    "    k = row_key(row) + \"|\" + seed + \"|\" + str(row[label_col])\n",
    "    h = hashlib.md5(k.encode(\"utf-8\")).hexdigest()\n",
    "    r = int(h, 16) / float(2**128)\n",
    "    # 0.0 to 0.7999 -> train, 0.8 to 0.8999 -> val, else test\n",
    "    if r < 0.8:\n",
    "        return \"train\"\n",
    "    elif r < 0.9:\n",
    "        return \"val\"\n",
    "    else:\n",
    "        return \"test\"\n",
    "\n",
    "# Counters\n",
    "n_train = n_val = n_test = 0\n",
    "\n",
    "for chunk in pd.read_csv(in_csv, chunksize=chunksize, usecols=usecols):\n",
    "    # Safety: if any key col missing in the file, create empty string column\n",
    "    for c in key_cols:\n",
    "        if c not in chunk.columns:\n",
    "            chunk[c] = \"\"\n",
    "\n",
    "    # Compute split per row\n",
    "    split = chunk.apply(assign_bucket, axis=1)\n",
    "\n",
    "    # Write each split\n",
    "    tmask = split == \"train\"\n",
    "    vmask = split == \"val\"\n",
    "    smask = split == \"test\"\n",
    "\n",
    "    if tmask.any():\n",
    "        chunk.loc[tmask].to_csv(train_csv, mode=\"w\" if first else \"a\", index=False, header=first)\n",
    "        n_train += int(tmask.sum())\n",
    "    if vmask.any():\n",
    "        chunk.loc[vmask].to_csv(val_csv, mode=\"w\" if first else \"a\", index=False, header=first)\n",
    "        n_val += int(vmask.sum())\n",
    "    if smask.any():\n",
    "        chunk.loc[smask].to_csv(test_csv, mode=\"w\" if first else \"a\", index=False, header=first)\n",
    "        n_test += int(smask.sum())\n",
    "\n",
    "    first = False  # headers written after first batch\n",
    "\n",
    "print(f\"Train: {n_train:,} rows -> {train_csv}\")\n",
    "print(f\"Val:   {n_val:,} rows -> {val_csv}\")\n",
    "print(f\"Test:  {n_test:,} rows -> {test_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and distribution:\n",
      "Ovary cancer cells: 80,115 (9.13%)\n",
      "Colon cancer cells: 80,115 (9.13%)\n",
      "T cells: 71,680 (8.17%)\n",
      "NK cells: 71,673 (8.17%)\n",
      "B cells: 66,106 (7.54%)\n",
      "Stem and progenitor cells: 61,619 (7.02%)\n",
      "Fibroblasts: 60,313 (6.88%)\n",
      "Myeloid cells: 58,714 (6.69%)\n",
      "Epithelial cells: 53,236 (6.07%)\n",
      "Endothelial cells: 49,530 (5.65%)\n",
      "Lung cancer cells: 48,547 (5.53%)\n",
      "Smooth muscle cells: 45,034 (5.13%)\n",
      "Pancreas cancer cells: 40,418 (4.61%)\n",
      "Oligodendrocytes: 24,559 (2.80%)\n",
      "Pericytes: 21,909 (2.50%)\n",
      "Stromal cells: 19,243 (2.19%)\n",
      "Liver cancer cells: 8,305 (0.95%)\n",
      "Microglia: 6,074 (0.69%)\n",
      "Astrocytes: 5,949 (0.68%)\n",
      "Neurons: 4,078 (0.46%)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/hpc/group/jilab/rz179/cellpt/combined/semi_balanced/full_train.csv\"\n",
    "label_col = \"cell_type\"\n",
    "\n",
    "counts = Counter()\n",
    "total = 0\n",
    "\n",
    "# Stream the CSV in chunks\n",
    "for chunk in pd.read_csv(file_path, usecols=[label_col], chunksize=100_000):\n",
    "    vals = chunk[label_col]\n",
    "    counts.update(vals)\n",
    "    total += len(vals)\n",
    "\n",
    "# Print results\n",
    "print(\"Counts and distribution:\")\n",
    "for label, count in counts.most_common():\n",
    "    pct = count / total * 100\n",
    "    print(f\"{label}: {count:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and distribution:\n",
      "Smooth muscle cells: 30,001 (8.57%)\n",
      "Fibroblasts: 30,001 (8.57%)\n",
      "Oligodendrocytes: 23,014 (6.58%)\n",
      "Colon cancer cells: 22,334 (6.38%)\n",
      "Ovary cancer cells: 22,333 (6.38%)\n",
      "T cells: 20,433 (5.84%)\n",
      "NK cells: 20,392 (5.83%)\n",
      "Stem and progenitor cells: 19,759 (5.65%)\n",
      "Endothelial cells: 19,759 (5.65%)\n",
      "Epithelial cells: 19,759 (5.65%)\n",
      "B cells: 19,339 (5.53%)\n",
      "Myeloid cells: 17,892 (5.11%)\n",
      "Lung cancer cells: 16,171 (4.62%)\n",
      "Pericytes: 15,923 (4.55%)\n",
      "Pancreas cancer cells: 14,416 (4.12%)\n",
      "Stromal cells: 14,306 (4.09%)\n",
      "Microglia: 7,290 (2.08%)\n",
      "Astrocytes: 7,131 (2.04%)\n",
      "Neurons: 5,134 (1.47%)\n",
      "Liver cancer cells: 4,613 (1.32%)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/hpc/group/jilab/rz179/cellpt/combined/subset_per_slide_two_eval_splits/subset_all.csv\"\n",
    "label_col = \"cell_type\"\n",
    "\n",
    "counts = Counter()\n",
    "total = 0\n",
    "\n",
    "# Stream the CSV in chunks\n",
    "for chunk in pd.read_csv(file_path, usecols=[label_col], chunksize=100_000):\n",
    "    vals = chunk[label_col]\n",
    "    counts.update(vals)\n",
    "    total += len(vals)\n",
    "\n",
    "# Print results\n",
    "print(\"Counts and distribution:\")\n",
    "for label, count in counts.most_common():\n",
    "    pct = count / total * 100\n",
    "    print(f\"{label}: {count:,} ({pct:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
